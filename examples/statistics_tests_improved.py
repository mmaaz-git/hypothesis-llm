"""Property-based tests for statistics module.
Generated by hypothesis-llm.
"""

import hypothesis
from hypothesis import given, strategies as st
from statistics import (
    mean,
    median,
    mode,
    stdev,
    variance
)



@given(st.floats(allow_nan=False, allow_infinity=False))
def test_single_element_identity_float(x):
    """Test that mean of single element equals that element for floats."""
    import math
    result = mean([x])
    assert math.isclose(result, x)



@given(st.lists(st.integers(), min_size=1))
def test_bounded_property(data):
    """Test that median is always between min and max of the data."""
    result = median(data)
    assert min(data) <= result <= max(data)



@given(st.integers())
def test_singleton_identity(x):
    """Test that median of single element list returns that element."""
    assert median([x]) == x



@given(st.lists(st.integers(), min_size=2, max_size=20).filter(lambda x: len(x) % 2 == 0))
def test_even_length_property(data):
    """Test that for even length data, median is average of two middle elements."""
    import math
    
    sorted_data = sorted(data)
    n = len(sorted_data)
    i = n // 2
    expected = (sorted_data[i - 1] + sorted_data[i]) / 2
    result = median(data)
    
    assert math.isclose(result, expected)



@given(st.lists(st.integers(), min_size=1, max_size=10), st.integers())
def test_translation_invariance(data, c):
    """Test that median(data + c) = median(data) + c."""
    import math
    
    translated_data = [x + c for x in data]
    
    original_median = median(data)
    translated_median = median(translated_data)
    
    assert math.isclose(translated_median, original_median + c)


@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2, max_size=20))
def test_stdev_non_negativity(data):
    """Test that standard deviation is always non-negative."""
    result = stdev(data)
    assert result >= 0



@given(st.floats(allow_nan=False, allow_infinity=False), st.integers(min_value=2, max_value=20))
def test_variance_zero_for_constant_data(constant, size):
    """Test that variance is zero when all data points are identical."""
    data = [constant] * size
    result = variance(data)
    import math
    assert math.isclose(result, 0, abs_tol=1e-10), f"Variance of constant data should be 0, got {result}"


@given(st.lists(st.integers(min_value=-1000, max_value=1000), min_size=2, max_size=20))
def test_stdev_equals_sqrt_variance_integers(data):
    """Test that stdev(data) = âˆšvariance(data) for integer data.
    
    This tests the fundamental relationship using integer inputs which
    should produce exact results within floating point precision.
    """
    import math
    
    var_result = variance(data)
    stdev_result = stdev(data)
    expected_stdev = math.sqrt(var_result)
    
    # Use math.isclose for floating point comparison
    assert math.isclose(stdev_result, expected_stdev, rel_tol=1e-14)


@given(st.lists(st.fractions(min_value=-100, max_value=100), min_size=2, max_size=20))
def test_variance_with_precomputed_mean_equals_variance_without_mean_fractions(data):
    """
    Test that variance(data, mean(data)) equals variance(data) for Fraction data.
    
    Using Fraction data to test the same property with exact rational arithmetic,
    ensuring no floating point precision issues.
    """
    from statistics import variance, mean
    
    # Compute mean of the data
    data_mean = mean(data)
    
    # Compute variance with and without pre-computed mean
    variance_without_mean = variance(data)
    variance_with_mean = variance(data, data_mean)
    
    # Should be exactly equal for Fraction data
    assert variance_without_mean == variance_with_mean



@given(st.lists(st.fractions(min_value=-100, max_value=100), min_size=2, max_size=20))
def test_stdev_with_mean_equals_stdev_without_mean_fractions(data):
    """
    Test the stdev property with Fraction data for exact arithmetic.
    
    Fractions provide exact rational arithmetic, eliminating floating point
    precision concerns and ensuring the property holds exactly.
    """
    import statistics
    from fractions import Fraction
    
    # Filter out cases where all values are the same (stdev would be 0)
    if len(set(data)) < 2:
        return
    
    # Calculate stdev without providing mean
    stdev_without_mean = statistics.stdev(data)
    
    # Calculate mean and provide it to stdev  
    data_mean = statistics.mean(data)
    stdev_with_mean = statistics.stdev(data, data_mean)
    
    # Results should be exactly equal for Fraction inputs
    assert stdev_without_mean == stdev_with_mean



@given(st.floats(allow_nan=False, allow_infinity=False))
def test_variance_zero_for_identical_elements(value):
    """
    Test the specific case where all elements are identical - variance should be exactly zero.
    """
    import math
    
    # Create data with identical elements
    data = [value] * 5  # Use 5 identical elements
    
    var = variance(data)
    data_mean = mean(data)
    
    # All elements should equal the mean
    assert math.isclose(data_mean, value, rel_tol=1e-9, abs_tol=1e-9)
    
    # Variance should be zero
    assert math.isclose(var, 0, abs_tol=1e-9), f"Variance of identical elements should be zero, got {var}"



@given(st.lists(st.integers(-1000, 1000), min_size=2, max_size=50))
def test_variance_non_negative_with_integers(data):
    """
    Test variance non-negativity property with integer data to avoid floating point issues.
    """
    var = variance(data)
    data_mean = mean(data)
    
    # Variance is always non-negative
    assert var >= 0, f"Variance should be non-negative, got {var}"
    
    # Check zero variance condition: all elements must be equal
    all_elements_equal = all(x == data[0] for x in data)
    
    if all_elements_equal:
        assert var == 0, f"Variance should be zero for identical elements, got {var}"
    else:
        assert var > 0, f"Variance should be positive for non-identical elements, got {var}"



@given(st.lists(st.integers(), min_size=1, max_size=1))
def test_mode_single_element_dataset(data):
    """
    Test the edge case where the dataset contains exactly one element.
    This is technically a case with no repeated values, and should return that single element.
    """
    from statistics import mode
    
    result = mode(data)
    
    # With a single element, that element is both the first occurrence and the only choice
    assert result == data[0], f"Expected the single element {data[0]}, got {result}"

@given(st.lists(st.integers(min_value=-2**53, max_value=2**53), min_size=1))
def test_arithmetic_mean_formula(data):
    """Test that mean equals sum of elements divided by count."""
    import math
    
    result = mean(data)
    expected = sum(data) / len(data)
    
    # Handle edge cases where the result might be infinity
    if math.isinf(expected) and math.isinf(result):
        assert math.copysign(1, result) == math.copysign(1, expected)  # Check same sign of infinity
    else:
        assert math.isclose(result, expected, rel_tol=1e-15)

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e10, max_value=1e10), min_size=1))
def test_arithmetic_mean_formula_floats(data):
    """Test arithmetic mean formula for floats using approximate equality."""
    import math
    from statistics import mean
    result = mean(data)
    expected = sum(data) / len(data)
    assert math.isclose(result, expected, rel_tol=1e-9, abs_tol=1e-12)

@given(st.lists(st.integers(), min_size=1))
def test_commutativity(data):
    """Test that mean is invariant under permutation of elements."""
    import math
    from random import shuffle
    from statistics import mean
    
    original_mean = mean(data)
    shuffled_data = data.copy()
    shuffle(shuffled_data)
    assert math.isclose(mean(shuffled_data), original_mean)

def test_empty_input_exception():
    """Test that mean raises StatisticsError for empty input."""
    import pytest
    from statistics import mean, StatisticsError
    
    with pytest.raises(StatisticsError):
        mean([])

@given(st.integers(min_value=-10**10, max_value=10**10))
def test_single_element_identity_int(x):
    """Test that mean of single element equals that element."""
    import math
    assert math.isclose(mean([x]), x)

@given(st.integers(), st.integers(min_value=1, max_value=100))
def test_constant_value_property(c, n):
    """Test that mean of n identical values equals that value."""
    import math
    data = [c] * n
    assert math.isclose(mean(data), c, rel_tol=1e-10, abs_tol=1e-10)

@given(st.lists(st.integers(min_value=-1e10, max_value=1e10), min_size=1), 
       st.integers(min_value=-1e6, max_value=1e6).filter(lambda x: x != 0))
def test_linear_transformation(data, k):
    """Test that mean scales linearly: mean(k*data) = k * mean(data)."""
    import math
    from statistics import mean
    
    scaled_data = [k * x for x in data]
    result = mean(scaled_data)
    expected = k * mean(data)
    assert math.isclose(result, expected, rel_tol=1e-9)

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1), 
       k=st.floats(allow_nan=False, allow_infinity=False))
def test_linear_transformation_floats(data, k):
    """Test linear transformation property for floats."""
    import math
    from statistics import mean
    scaled_data = [k * x for x in data]
    result = mean(scaled_data)
    expected = k * mean(data)
    assert math.isclose(result, expected)

@given(st.lists(st.integers(), min_size=1), st.integers())
def test_translation_property(data, c):
    """Test that mean(data + c) = mean(data) + c."""
    import math
    from statistics import mean
    
    translated_data = [x + c for x in data]
    result = mean(translated_data)
    expected = mean(data) + c
    assert math.isclose(result, expected, rel_tol=1e-9, abs_tol=1e-12)

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1), c=st.floats(allow_nan=False, allow_infinity=False))
def test_translation_property_floats(data, c):
    """Test translation property for floats."""
    import math
    from statistics import mean
    translated_data = [x + c for x in data]
    result = mean(translated_data)
    expected = mean(data) + c
    assert math.isclose(result, expected)

@given(st.lists(st.integers(), min_size=1))
def test_boundedness(data):
    """Test that min(data) <= mean(data) <= max(data) with floating-point tolerance."""
    import math
    from statistics import mean
    
    result = mean(data)
    min_val = min(data)
    max_val = max(data)
    
    # Use small epsilon for floating-point comparison tolerance
    epsilon = 1e-10
    assert min_val - epsilon <= result <= max_val + epsilon

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1))
def test_boundedness_floats(data):
    """Test boundedness property for floats."""
    import math
    
    result = mean(data)
    min_val = min(data)
    max_val = max(data)
    
    # Handle floating-point precision issues by allowing small epsilon differences
    # or using math.isclose() when result is very close to boundaries
    epsilon = 1e-10
    
    if math.isclose(result, min_val, rel_tol=1e-9, abs_tol=1e-10):
        # Result is very close to minimum, allow for floating-point precision
        assert result >= min_val - epsilon
    elif math.isclose(result, max_val, rel_tol=1e-9, abs_tol=1e-10):
        # Result is very close to maximum, allow for floating-point precision
        assert result <= max_val + epsilon
    else:
        # Standard boundedness check with epsilon tolerance
        assert min_val - epsilon <= result <= max_val + epsilon

@given(st.lists(st.fractions(), min_size=1))
def test_type_preservation_fractions(data):
    """Test that fractions return fractions."""
    from fractions import Fraction
    from statistics import mean
    result = mean(data)
    assert isinstance(result, Fraction)

@given(st.lists(st.decimals(allow_nan=False, allow_infinity=False), min_size=1))
def test_type_preservation_decimals(data):
    """Test that decimals return decimals."""
    from decimal import Decimal
    from statistics import mean
    result = mean(data)
    assert isinstance(result, Decimal)

@given(st.lists(st.integers(), min_size=2))
def test_monotonicity_under_replacement(data):
    """Test that replacing smaller element with larger increases mean."""
    from statistics import mean
    
    original_mean = mean(data)
    min_val = min(data)
    max_val = max(data)
    
    if min_val < max_val:
        # Replace first occurrence of min with max
        modified_data = data.copy()
        min_index = modified_data.index(min_val)
        modified_data[min_index] = max_val
        new_mean = mean(modified_data)
        assert new_mean > original_mean

@given(st.lists(st.integers(min_value=-2**53, max_value=2**53), min_size=1), 
       st.lists(st.integers(min_value=-2**53, max_value=2**53), min_size=1))
def test_concatenation_property(list1, list2):
    """Test weighted average property for concatenated lists."""
    import math
    from statistics import mean
    
    combined = list1 + list2
    combined_mean = mean(combined)
    
    expected = (len(list1) * mean(list1) + len(list2) * mean(list2)) / (len(list1) + len(list2))
    assert math.isclose(combined_mean, expected, rel_tol=1e-15, abs_tol=1e-15)

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1),
       st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1))
def test_concatenation_property_floats(list1, list2):
    """Test concatenation property for floats."""
    import math
    from statistics import mean
    
    combined = list1 + list2
    combined_mean = mean(combined)
    
    expected = (len(list1) * mean(list1) + len(list2) * mean(list2)) / (len(list1) + len(list2))
    assert math.isclose(combined_mean, expected, rel_tol=1e-9, abs_tol=1e-12)

@given(st.lists(st.one_of(st.integers(), st.floats(allow_nan=False, allow_infinity=False)), min_size=1))
def test_mixed_numeric_types(mixed_numbers):
    """Test that mixed numeric types are handled appropriately using property-based testing."""
    from fractions import Fraction
    from decimal import Decimal
    from statistics import mean
    import math
    
    # Property 1: Mean of mixed int/float should always be float
    result = mean(mixed_numbers)
    assert isinstance(result, float)
    
    # Property 2: Result should be within expected bounds
    min_val = min(mixed_numbers)
    max_val = max(mixed_numbers)
    assert min_val <= result <= max_val
    
    # Property 3: Mean should equal sum divided by length
    expected = sum(mixed_numbers) / len(mixed_numbers)
    assert math.isclose(result, expected, rel_tol=1e-9)

@given(st.lists(st.integers().map(lambda x: Fraction(x, 1)), min_size=1))
def test_fraction_types(fractions_list):
    """Test that fractions maintain their type in mean calculation."""
    from fractions import Fraction
    from statistics import mean
    
    result = mean(fractions_list)
    assert isinstance(result, Fraction)
    
    # Property: Result should be within bounds
    min_val = min(fractions_list)
    max_val = max(fractions_list)
    assert min_val <= result <= max_val

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False).map(lambda x: Decimal(str(x))), min_size=1))
def test_decimal_types(decimals_list):
    """Test that decimals maintain their type in mean calculation."""
    from decimal import Decimal
    from statistics import mean
    
    result = mean(decimals_list)
    assert isinstance(result, Decimal)
    
    # Property: Result should be within bounds
    min_val = min(decimals_list)
    max_val = max(decimals_list)
    assert min_val <= result <= max_val

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6), min_size=1000, max_size=10000))
def test_numerical_stability_large_datasets(data):
    """Test that mean handles reasonably large datasets without overflow."""
    import math
    
    result = mean(data)
    # Result should be finite for reasonable inputs
    assert math.isfinite(result), f"Mean of large dataset should be finite, got {result}"
    
    # Additional sanity check: result should be within reasonable bounds of input range
    min_val = min(data)
    max_val = max(data)
    assert min_val <= result <= max_val, f"Mean {result} should be between min {min_val} and max {max_val}"

@given(st.lists(st.integers(), min_size=1))
def test_order_independence(data):
    """Test that median is invariant under permutation of input data."""
    from statistics import median
    from hypothesis.strategies import permuted
    
    shuffled_data = permuted(data).example()
    assert median(data) == median(shuffled_data)

@given(st.lists(st.integers(), min_size=1, max_size=20).filter(lambda x: len(x) % 2 == 1))
def test_odd_length_property(data):
    """Test that for odd length data, median is the middle element when sorted."""
    from statistics import median
    result = median(data)
    sorted_data = sorted(data)
    assert result == sorted_data[len(data) // 2]

def test_empty_data_exception():
    """Test that median raises StatisticsError for empty data."""
    import statistics
    try:
        median([])
        assert False, "Should have raised StatisticsError"
    except statistics.StatisticsError:
        pass  # Expected exception
    except Exception as e:
        assert False, f"Expected StatisticsError but got {type(e).__name__}: {e}"

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1, max_size=100))
def test_monotonicity(data):
    """Test that median is between min and max of the data."""
    from statistics import median
    
    result = median(data)
    assert min(data) <= result <= max(data)

@given(st.lists(st.integers(), min_size=1, max_size=10))
def test_duplicate_invariance(data):
    """Test that median of data where all elements are duplicated equally equals original median."""
    from statistics import median
    
    original_median = median(data)
    
    # Duplicate ALL elements equally (each element appears twice)
    data_with_duplicates = data + data
    
    assert median(data_with_duplicates) == original_median

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1), 
       k=st.floats(min_value=0.01, max_value=1000, allow_nan=False, allow_infinity=False))
def test_scale_invariance(data, k):
    """Test that median(k * data) = k * median(data) for positive k."""
    import math
    from statistics import median
    
    # Filter out any remaining non-finite values that might have slipped through
    data = [x for x in data if math.isfinite(x)]
    
    # Skip if we don't have valid data after filtering
    if len(data) == 0:
        return
    
    scaled_data = [k * x for x in data]
    
    original_median = median(data)
    scaled_median = median(scaled_data)
    
    assert math.isclose(scaled_median, k * original_median, rel_tol=1e-9)

@given(st.lists(st.integers(), min_size=1, max_size=9).filter(lambda x: len(x) % 2 == 1))
def test_reflection_property(data):
    """Test that median(-data) = -median(data) for odd-length lists."""
    import math
    from statistics import median
    
    negated_data = [-x for x in data]
    
    original_median = median(data)
    negated_median = median(negated_data)
    
    assert math.isclose(negated_median, -original_median)

@given(st.lists(st.integers(), min_size=3, max_size=10))
def test_robustness_to_outliers(data):
    """Test that changing extreme values beyond existing min/max doesn't change median."""
    from statistics import median
    
    original_median = median(data)
    
    # Create outliers beyond existing range
    data_min, data_max = min(data), max(data)
    outlier_data = data.copy()
    
    if len(outlier_data) >= 3:
        # Find indices before any modifications
        min_idx = outlier_data.index(min(outlier_data))
        max_idx = outlier_data.index(max(outlier_data))
        
        # If min and max are the same index, find a different index for max
        if min_idx == max_idx and len(outlier_data) > 1:
            remaining_indices = [i for i in range(len(outlier_data)) if i != min_idx]
            max_idx = remaining_indices[0]  # Pick any different index
        
        # Replace with outliers (order matters to avoid interference)
        if min_idx != max_idx:
            outlier_data[min_idx] = data_min - 1000
            outlier_data[max_idx] = data_max + 1000
        else:
            # All elements are the same, just replace one
            outlier_data[min_idx] = data_min - 1000
    
    outlier_median = median(outlier_data)
    
    assert original_median == outlier_median

@given(st.lists(st.integers(), min_size=1))
def test_result_must_be_element_of_input(data):
    """Test that mode(data) is always an element of the input data for non-empty data."""
    from statistics import mode, StatisticsError
    
    try:
        result = mode(data)
        # mode() returns a single value that should be in the input data
        assert result in data
    except StatisticsError:
        # mode() raises StatisticsError when there's no unique mode
        # This is expected behavior for multimodal datasets, so we pass
        pass

def test_empty_input_raises_exception():
    """Test that mode([]) raises StatisticsError for empty input."""
    import statistics
    import pytest
    
    with pytest.raises(statistics.StatisticsError):
        statistics.mode([])

@given(st.one_of(st.integers(), st.text(), st.floats(allow_nan=False, allow_infinity=False)))
def test_single_element_invariant(x):
    """Test that mode([x]) contains x as the single mode for any single element."""
    from statistics import mode
    import math
    
    result = mode([x])
    
    # For single element lists, mode should return that element
    # Handle floating-point comparison separately due to precision issues
    if isinstance(x, float) and isinstance(result, float):
        assert math.isclose(result, x), f"Expected mode to be close to {x}, got {result}"
    else:
        assert result == x, f"Expected mode to be {x}, got {result}"

@given(st.lists(st.integers(), min_size=1))
def test_order_invariance_with_unique_mode(data):
    """Test that mode is invariant under permutation when there's a unique mode."""
    from collections import Counter
    from statistics import mode
    
    # Check if there's a unique mode (highest frequency appears only once)
    counts = Counter(data)
    max_count = max(counts.values())
    modes_with_max_count = [item for item, count in counts.items() if count == max_count]
    
    if len(modes_with_max_count) == 1:
        # There's a unique mode, test order invariance
        original_mode = mode(data)
        # Use Hypothesis's deterministic approach to create a permutation
        shuffled_data = sorted(data, key=lambda x: (x % 7, -x))  # Deterministic reordering
        assert mode(shuffled_data) == original_mode

@given(st.lists(st.integers(), min_size=1))
def test_frequency_preservation(data):
    """Test that if x = mode(data), then count(x, data) >= count(y, data) for all y in data."""
    from statistics import mode
    
    result = mode(data)
    result_count = data.count(result)
    
    # Find the maximum frequency among all elements
    max_count = max(data.count(x) for x in set(data))
    
    # The returned mode should have the maximum frequency
    assert result_count == max_count

@given(st.one_of(st.integers(), st.text()).filter(lambda x: x != "different"))
def test_tie_breaking_consistency(element):
    """Test that mode returns the first occurrence when there are tied elements."""
    # Create data where two elements have the same frequency
    data = [element, element, "different", "different"]
    result = mode(data)
    # The mode should be the first element since both have count 2
    assert result == element

@given(st.lists(st.integers(), min_size=1), st.integers())
def test_duplication_irrelevance_for_unique_mode(data, x):
    """Test that if x is already the unique mode, adding more x's doesn't change the result."""
    from collections import Counter
    from statistics import mode
    
    # Only test when x is in data and is the unique mode
    if x not in data:
        return
        
    try:
        original_mode = mode(data)
        if original_mode != x:
            return
            
        # Verify x is truly the unique mode
        counts = Counter(data)
        x_count = counts[x]
        other_counts = [count for item, count in counts.items() if item != x]
        if other_counts and max(other_counts) >= x_count:
            return  # x is not unique mode
            
        # Now test the property
        extended_data = data + [x, x, x]
        assert mode(extended_data) == x
    except:
        # Skip if mode() fails on original data
        return

@given(st.one_of(st.lists(st.integers(), min_size=1), st.lists(st.text(), min_size=1)))
def test_type_preservation(data):
    """Test that the type of mode(data) matches the type of elements in data and is actually the statistical mode."""
    from statistics import mode
    from collections import Counter
    
    result = mode(data)
    
    # The result should have the same type as the elements in data (homogeneous)
    element_types = set(type(x) for x in data)
    assert len(element_types) == 1, "Data should be homogeneous"
    assert type(result) in element_types
    
    # Verify the result is actually the statistical mode (most frequent element)
    counter = Counter(data)
    max_count = max(counter.values())
    most_frequent_elements = [elem for elem, count in counter.items() if count == max_count]
    assert result in most_frequent_elements

@given(st.lists(st.integers(), min_size=2))
def test_subset_property_violation(data):
    """Test that mode(subset) may not equal mode(superset) - this is expected behavior."""
    from statistics import mode
    
    # This test demonstrates that the subset property doesn't hold for mode
    # We create a subset that is guaranteed to be non-empty
    subset = data[:max(1, len(data)//2)]
    
    subset_mode = mode(subset)
    superset_mode = mode(data)
    
    # We don't assert equality - we just verify both calls work
    # This property violation is expected and correct behavior
    assert subset_mode in subset
    assert superset_mode in data
    
    # Track when the property violation occurs to demonstrate it can happen
    if subset_mode != superset_mode:
        # This is the expected property violation - subset mode can differ from superset mode
        pass

@given(st.lists(st.integers(), min_size=1))
def test_monotonicity_absence(data):
    """Test that adding elements can change the mode arbitrarily."""
    from statistics import mode
    
    original_mode = mode(data)
    
    # Add a new element that doesn't appear in original data
    new_element = max(data) + 1 if data else 1
    # Add it enough times to make it the new mode
    extended_data = data + [new_element] * (len(data) + 1)
    new_mode = mode(extended_data)
    
    # The mode can change when we add elements (monotonicity doesn't hold)
    assert new_mode == new_element
    assert new_mode != original_mode

@given(st.lists(st.integers(), min_size=1))
def test_idempotency_for_single_mode_datasets(data):
    """Test that if data has unique mode x, then mode(data + data) = x."""
    from collections import Counter
    from statistics import mode, multimode
    
    counts = Counter(data)
    max_count = max(counts.values())
    modes_with_max_count = [item for item, count in counts.items() if count == max_count]
    
    if len(modes_with_max_count) == 1:
        # There's a unique mode
        original_mode = mode(data)
        # Validate that the mode function returns the correct value
        assert original_mode in modes_with_max_count
        
        doubled_data = data + data
        doubled_mode = mode(doubled_data)
        assert doubled_mode == original_mode
    else:
        # Multi-modal case: test that multimode returns all modes
        original_modes = multimode(data)
        # Validate that multimode returns the correct modes
        assert set(original_modes) == set(modes_with_max_count)
        
        doubled_data = data + data
        doubled_modes = multimode(doubled_data)
        # After doubling, the modes should remain the same
        assert set(doubled_modes) == set(original_modes)

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2, max_size=20))
def test_stdev_zero_iff_all_equal(data):
    """Test that stdev is zero if and only if all elements are equal."""
    import math
    from statistics import stdev
    
    result = stdev(data)
    all_equal = len(set(data)) == 1
    is_zero = math.isclose(result, 0, abs_tol=1e-10)
    
    # Test the if-and-only-if relationship
    assert all_equal == is_zero

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e10, max_value=1e10), min_size=2), 
       k=st.floats(allow_nan=False, allow_infinity=False, min_value=-1e10, max_value=1e10).filter(lambda x: abs(x) > 1e-10))
def test_stdev_scale_invariance(data, k):
    """Test that stdev(k*data) = |k| * stdev(data)."""
    import math
    from statistics import stdev
    
    # Skip cases where all data points are identical (stdev would be 0)
    if len(set(data)) < 2:
        return
    
    scaled_data = [k * x for x in data]
    original_stdev = stdev(data)
    scaled_stdev = stdev(scaled_data)
    expected = abs(k) * original_stdev
    
    assert math.isclose(scaled_stdev, expected, rel_tol=1e-9)

@given(
    st.lists(
        st.floats(min_value=-1e10, max_value=1e10, allow_nan=False, allow_infinity=False), 
        min_size=2
    ), 
    st.floats(min_value=-1e10, max_value=1e10, allow_nan=False, allow_infinity=False)
)
def test_stdev_translation_invariance(data, k):
    """Test that stdev(data + k) = stdev(data) for scalar k."""
    import math
    from statistics import stdev
    
    translated_data = [x + k for x in data]
    original_stdev = stdev(data)
    translated_stdev = stdev(translated_data)
    
    assert math.isclose(translated_stdev, original_stdev, rel_tol=1e-9, abs_tol=1e-15)

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=0, max_size=1))
def test_stdev_minimum_sample_size_requirement(data):
    """Test that stdev raises StatisticsError when len(data) < 2."""
    from statistics import StatisticsError, stdev
    
    # Verify that our generated data actually has less than 2 elements
    assert len(data) < 2, f"Test data should have less than 2 elements, got {len(data)}"
    
    try:
        stdev(data)
        assert False, "Expected StatisticsError for data with less than 2 elements"
    except StatisticsError:
        pass  # Expected behavior

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2, max_size=20),
       indices=st.data())
def test_stdev_order_invariance(data, indices):
    """Test that stdev is invariant under permutation of data."""
    import math
    from statistics import stdev
    
    original_stdev = stdev(data)
    
    # Create a shuffled copy using Hypothesis's deterministic permutation
    shuffled_data = indices.draw(st.permutations(data))
    shuffled_stdev = stdev(shuffled_data)
    
    assert math.isclose(original_stdev, shuffled_stdev, rel_tol=1e-10)

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2, max_size=20))
def test_stdev_upper_bound_by_range(data):
    """Test that stdev â‰¤ (max - min)/2 * sqrt(2(n-1)/n)."""
    import math
    from statistics import stdev
    
    if len(set(data)) == 1:  # All elements equal
        return  # Skip this test case as bound doesn't apply meaningfully
        
    n = len(data)
    data_range = max(data) - min(data)
    upper_bound = (data_range / 2) * math.sqrt(2 * (n - 1) / n)
    result = stdev(data)
    
    assert result <= upper_bound + 1e-10  # Small tolerance for floating point

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e100, max_value=1e100), min_size=2, max_size=20))
def test_stdev_consistency_with_variance(data):
    """Test that stdev(data) = sqrt(variance(data))."""
    import math
    from statistics import variance, stdev
    
    stdev_result = stdev(data)
    variance_result = variance(data)
    expected = math.sqrt(variance_result)
    
    assert math.isclose(stdev_result, expected, rel_tol=1e-9)

@given(
    base_data=st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1000, max_value=1000), min_size=2, max_size=100),
    spread_factor=st.floats(min_value=1.01, max_value=10, allow_nan=False, allow_infinity=False)
)
def test_stdev_monotonicity_under_data_spread(base_data, spread_factor):
    """Test that more spread out data has larger standard deviation."""
    import math
    from statistics import mean, stdev
    
    # Create data with same mean but larger deviations
    data_mean = mean(base_data)
    more_spread_data = [data_mean + spread_factor * (x - data_mean) for x in base_data]
    
    original_stdev = stdev(base_data)
    spread_stdev = stdev(more_spread_data)
    
    # Only test if original has meaningful spread (not constant data)
    if original_stdev > 1e-10:
        assert spread_stdev > original_stdev
    else:
        # If original data is constant, spread data should have zero stdev too
        assert math.isclose(spread_stdev, 0, abs_tol=1e-10)

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e50, max_value=1e50), min_size=2, max_size=20))
def test_stdev_robustness_to_xbar_parameter(data):
    """Test that providing the true sample mean as xbar gives same result."""
    import math
    from statistics import mean, stdev
    
    sample_mean = mean(data)
    result_without_xbar = stdev(data)
    result_with_xbar = stdev(data, xbar=sample_mean)
    
    assert math.isclose(result_without_xbar, result_with_xbar, rel_tol=1e-10)

@given(
    data=st.lists(
        st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6), 
        min_size=2, 
        max_size=100
    ).filter(lambda x: len(set(x)) > 1),  # Ensure non-zero variance
    outlier_magnitude=st.floats(
        allow_nan=False, 
        allow_infinity=False, 
        min_value=-1e6, 
        max_value=1e6
    ).filter(lambda x: abs(x) > 1e-6)  # Ensure outlier is meaningfully different from mean
)
def test_stdev_effect_of_outliers(data, outlier_magnitude):
    """Test that adding an outlier increases standard deviation (unless outlier equals mean)."""
    import math
    from statistics import mean, stdev
    
    original_stdev = stdev(data)
    data_mean = mean(data)
    
    # Add outlier far from mean
    outlier = data_mean + outlier_magnitude
    data_with_outlier = data + [outlier]
    new_stdev = stdev(data_with_outlier)
    
    # Use approximate comparison to handle floating point precision issues
    assert new_stdev > original_stdev or math.isclose(new_stdev, original_stdev, rel_tol=1e-9)
    
    # Since we filtered for meaningful outlier_magnitude, it should actually increase
    assert new_stdev > original_stdev

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e100, max_value=1e100), min_size=2, max_size=100))
def test_variance_non_negativity(data):
    """Test that variance is always non-negative for all valid inputs."""
    from statistics import variance
    result = variance(data)
    assert result >= 0, f"Variance should be non-negative, got {result}"

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1), 
       k=st.floats(allow_nan=False, allow_infinity=False))
def test_variance_translation_invariance(data, k):
    """Test that adding a constant to all data points doesn't change variance."""
    import math
    from statistics import variance
    
    translated_data = [x + k for x in data]
    original_var = variance(data)
    translated_var = variance(translated_data)
    assert math.isclose(original_var, translated_var, rel_tol=1e-10), \
        f"Translation invariance failed: original={original_var}, translated={translated_var}"

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2), 
       k=st.floats(allow_nan=False, allow_infinity=False).filter(lambda x: x != 0))
def test_variance_scale_transformation(data, k):
    """Test that scaling data by constant k scales variance by kÂ²."""
    import math
    from statistics import variance
    
    scaled_data = [k * x for x in data]
    original_var = variance(data)
    scaled_var = variance(scaled_data)
    expected_var = k * k * original_var
    assert math.isclose(scaled_var, expected_var, rel_tol=1e-9), \
        f"Scale transformation failed: scaled_var={scaled_var}, expected={expected_var}"

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e100, max_value=1e100), min_size=2, max_size=100))
def test_variance_consistent_with_provided_mean(data):
    """Test that providing correct mean gives same result as automatic calculation."""
    from statistics import mean, variance
    import math
    
    data_mean = mean(data)
    var_auto = variance(data)
    var_with_mean = variance(data, data_mean)
    
    assert math.isclose(var_auto, var_with_mean, rel_tol=1e-10), \
        f"Variance with provided mean should match automatic: auto={var_auto}, with_mean={var_with_mean}"

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e10, max_value=1e10), min_size=2, max_size=20))
def test_variance_order_invariance(data):
    """Test that variance is invariant to order of data points."""
    import random
    import math
    from statistics import variance
    
    original_var = variance(data)
    shuffled_data = data.copy()
    random.shuffle(shuffled_data)
    shuffled_var = variance(shuffled_data)
    
    assert math.isclose(original_var, shuffled_var, rel_tol=1e-12), \
        f"Order invariance failed: original={original_var}, shuffled={shuffled_var}"

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=0, max_size=1))
def test_variance_minimum_sample_size_requirement(data):
    """Test that variance raises StatisticsError for data with less than 2 points."""
    from statistics import StatisticsError, variance
    import pytest
    
    if len(data) < 2:
        with pytest.raises(StatisticsError):
            variance(data)
    else:
        # This branch won't be reached with current strategy, but good for clarity
        variance(data)  # Should not raise

@given(st.lists(st.floats(min_value=-1e10, max_value=1e10, allow_nan=False, allow_infinity=False), min_size=2, max_size=50))
def test_variance_bessels_correction(data):
    """Test that variance uses (n-1) denominator (Bessel's correction) instead of n."""
    from statistics import mean, variance
    import math
    
    n = len(data)
    data_mean = mean(data)
    
    # Calculate population variance (with n denominator)
    sum_sq_dev = sum((x - data_mean) ** 2 for x in data)
    population_var = sum_sq_dev / n
    
    # Sample variance should use (n-1) denominator
    expected_sample_var = sum_sq_dev / (n - 1)
    actual_var = variance(data)
    
    assert math.isclose(actual_var, expected_sample_var, rel_tol=1e-8, abs_tol=1e-15), \
        f"Bessel's correction not applied: expected={expected_sample_var}, actual={actual_var}"
    
    # Should be different from population variance (unless n=1, but we have nâ‰¥2)
    if n > 2:
        assert not math.isclose(actual_var, population_var, rel_tol=1e-6), \
            "Sample variance should differ from population variance due to Bessel's correction"

@given(st.lists(st.integers(min_value=-1000, max_value=1000), min_size=2, max_size=20))
def test_variance_type_preservation_integers(int_data):
    """Test that variance preserves numeric types when possible (integer input)."""
    from fractions import Fraction
    from statistics import variance
    
    result = variance(int_data)
    # For integer input, result should be a Fraction or float (variance is rarely an integer)
    assert isinstance(result, (Fraction, float)), \
        f"Expected Fraction/float for integer input, got {type(result)}"

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e100, max_value=1e100), min_size=2, max_size=50))
def test_variance_handles_duplicate_values(data):
    """Test that variance correctly handles repeated values in the dataset."""
    import math
    from statistics import variance
    
    # Add duplicates to the data
    data_with_duplicates = data + data[:min(len(data), 5)]  # Add some duplicates
    
    # Should not raise an error and should give finite result
    result = variance(data_with_duplicates)
    assert result >= 0
    assert math.isfinite(result)

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e50, max_value=1e50), min_size=2, max_size=100))
def test_variance_finite_for_finite_input(data):
    """Test that variance produces finite results for finite input data."""
    import math
    from statistics import variance
    
    result = variance(data)
    assert math.isfinite(result), f"Expected finite variance for finite input, got {result}"

@given(st.lists(st.floats(min_value=-100, max_value=100, allow_nan=False, allow_infinity=False), min_size=2, max_size=10))
def test_variance_sensitivity_to_outliers(base_data):
    """Test that extreme values disproportionately increase variance."""
    import math
    from statistics import variance
    
    # Calculate base variance (skip if variance is 0 as outliers won't have multiplicative effect)
    base_var = variance(base_data)
    
    # Add outlier far from mean
    mean_val = sum(base_data) / len(base_data)
    outlier = mean_val + 100  # Large outlier
    data_with_outlier = base_data + [outlier]
    outlier_var = variance(data_with_outlier)
    
    # Variance should strictly increase with outlier
    assert outlier_var > base_var, \
        f"Variance should increase with outlier: base={base_var}, with_outlier={outlier_var}"

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6), min_size=2, max_size=50))
def test_variance_computational_stability_with_correct_mean(data):
    """Test that providing correct mean can improve numerical accuracy."""
    from statistics import mean, variance
    import math
    
    data_mean = mean(data)
    
    # Both should give the same result (within numerical precision)
    var_auto = variance(data)
    var_with_mean = variance(data, data_mean)
    
    # They should be very close (this tests computational stability)
    # Use more reasonable tolerance for floating-point arithmetic and add absolute tolerance
    assert math.isclose(var_auto, var_with_mean, rel_tol=1e-9, abs_tol=1e-15), \
        f"Providing correct mean should give same result: auto={var_auto}, with_mean={var_with_mean}"

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1000, max_value=1000), min_size=3, max_size=20))
def test_variance_monotonic_relationship_with_spread(data):
    """Test that more spread out data tends to have higher variance."""
    from statistics import variance, mean
    import math
    
    # Skip if all values are the same (variance would be 0)
    if len(set(data)) <= 1:
        return
    
    original_var = variance(data)
    data_mean = mean(data)
    
    # Create a more spread out version by scaling deviations from the mean
    spread_factor = 2.0
    spread_data = [data_mean + spread_factor * (x - data_mean) for x in data]
    spread_var = variance(spread_data)
    
    # The spread data should have higher variance (scaled by spread_factor^2)
    expected_spread_var = original_var * (spread_factor ** 2)
    
    assert spread_var > original_var, \
        f"More spread data should have higher variance: original={original_var}, spread={spread_var}"
    
    # Also verify the mathematical relationship holds
    assert math.isclose(spread_var, expected_spread_var, rel_tol=1e-10), \
        f"Variance should scale by spread_factor^2: expected={expected_spread_var}, actual={spread_var}"

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6), min_size=2, max_size=50))
def test_stdev_equals_sqrt_variance_floats(data):
    """Test that stdev(data) = âˆšvariance(data) for float data.
    
    This tests the fundamental relationship that standard deviation is the 
    square root of variance for the same dataset.
    """
    import math
    from statistics import variance, stdev
    
    var_result = variance(data)
    stdev_result = stdev(data)
    expected_stdev = math.sqrt(var_result)
    
    # Handle cases where values are very close to zero with absolute tolerance
    # and use relative tolerance for larger values
    assert math.isclose(stdev_result, expected_stdev, rel_tol=1e-14, abs_tol=1e-15)

@given(data=st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1), 
       xbar=st.floats(allow_nan=False, allow_infinity=False))
def test_stdev_equals_sqrt_variance_with_xbar(data, xbar):
    """Test that stdev(data, xbar) = âˆšvariance(data, xbar) when xbar is provided.
    
    This tests the relationship holds when an explicit mean value is provided
    to both functions.
    """
    import math
    from statistics import variance, stdev
    
    var_result = variance(data, xbar)
    stdev_result = stdev(data, xbar)
    expected_stdev = math.sqrt(var_result)
    
    # Use math.isclose for floating point comparison
    assert math.isclose(stdev_result, expected_stdev, rel_tol=1e-14)

@given(st.lists(st.decimals(min_value=-1000, max_value=1000, places=2), min_size=2, max_size=10))
def test_stdev_equals_sqrt_variance_decimals(data):
    """Test that stdev(data) = âˆšvariance(data) for Decimal data.
    
    This tests the relationship using Decimal inputs to verify the special
    handling for high-precision decimal arithmetic.
    """
    from decimal import Decimal
    from statistics import variance, stdev
    
    var_result = variance(data)
    stdev_result = stdev(data)
    
    # Keep everything in Decimal precision for proper high-precision testing
    expected_stdev = var_result.sqrt()
    
    # Verify both results are Decimal types (testing special Decimal handling)
    assert isinstance(var_result, Decimal), "Variance should return Decimal for Decimal input"
    assert isinstance(stdev_result, Decimal), "Standard deviation should return Decimal for Decimal input"
    
    # Compare Decimals directly with appropriate Decimal-based tolerance
    # Use relative tolerance appropriate for the precision of our input data (2 decimal places)
    tolerance = Decimal('1e-12')
    relative_error = abs(stdev_result - expected_stdev) / abs(expected_stdev)
    assert relative_error <= tolerance, f"stdev result {stdev_result} doesn't match sqrt(variance) {expected_stdev}"

@given(st.lists(st.fractions(min_value=-100, max_value=100), min_size=2, max_size=10).filter(lambda data: len(set(data)) > 1))
def test_stdev_equals_sqrt_variance_fractions(data):
    """Test that stdev(data) = âˆšvariance(data) for Fraction data.
    
    This tests the relationship using Fraction inputs to verify correct
    handling of rational number arithmetic. Ensures variance > 0 by
    filtering out constant sequences.
    """
    from fractions import Fraction
    from statistics import variance, stdev
    import math
    
    var_result = variance(data)
    stdev_result = stdev(data)
    
    # Keep calculations in Fraction domain as much as possible
    # Convert to float only for final comparison with appropriate tolerance
    expected_stdev = float(var_result) ** 0.5
    actual_stdev = float(stdev_result)
    
    # Use more lenient tolerance to account for Fractionâ†’float conversion precision loss
    assert math.isclose(actual_stdev, expected_stdev, rel_tol=1e-9, abs_tol=1e-12)

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e10, max_value=1e10), min_size=2, max_size=100))
def test_variance_with_precomputed_mean_equals_variance_without_mean(data):
    """
    Test that variance(data, mean(data)) equals variance(data).
    
    This property tests that when the mean is pre-computed and passed as the xbar
    parameter to variance(), the result should be identical to computing variance()
    without the xbar parameter (where mean is calculated internally).
    """
    import math
    from statistics import variance, mean
    
    # Compute mean of the data
    data_mean = mean(data)
    
    # Compute variance with and without pre-computed mean
    variance_without_mean = variance(data)
    variance_with_mean = variance(data, data_mean)
    
    # They should be equal (using close comparison for floating point)
    assert math.isclose(variance_without_mean, variance_with_mean, rel_tol=1e-12, abs_tol=1e-12)

@given(st.lists(st.integers(min_value=-1000, max_value=1000), min_size=2, max_size=50))
def test_variance_with_precomputed_mean_equals_variance_without_mean_integers(data):
    """
    Test that variance(data, mean(data)) equals variance(data) for integer data.
    
    Using integer data to test the same property, which should give approximate equality
    since the statistics module performs floating-point arithmetic internally.
    """
    import math
    from statistics import variance, mean
    
    # Compute mean of the data
    data_mean = mean(data)
    
    # Compute variance with and without pre-computed mean
    variance_without_mean = variance(data)
    variance_with_mean = variance(data, data_mean)
    
    # Should be approximately equal due to floating-point arithmetic
    assert math.isclose(variance_without_mean, variance_with_mean, rel_tol=1e-9)

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2, max_size=100))
def test_stdev_with_mean_equals_stdev_without_mean(data):
    """
    Test that stdev(data, mean(data)) equals stdev(data).
    
    This property holds because the stdev function internally uses the same
    calculation whether the mean is provided explicitly or calculated internally.
    When xbar (mean) is provided, it should yield identical results to when
    stdev calculates the mean itself.
    """
    import statistics
    import math
    
    # Calculate stdev without providing mean (let it calculate internally)
    stdev_without_mean = statistics.stdev(data)
    
    # Calculate mean separately and provide it to stdev
    data_mean = statistics.mean(data)
    stdev_with_mean = statistics.stdev(data, data_mean)
    
    # Both calculations should yield the same result
    assert math.isclose(stdev_without_mean, stdev_with_mean, rel_tol=1e-12)

@given(st.lists(st.integers(min_value=-1000, max_value=1000), min_size=2, max_size=50))
def test_stdev_with_mean_equals_stdev_without_mean_integers(data):
    """
    Test the stdev property with integer data to avoid floating point precision issues.
    
    Using integers ensures that the mean calculation is exact and any differences
    would be due to the property not holding rather than floating point errors.
    """
    import statistics
    import math
    
    # Calculate stdev without providing mean
    stdev_without_mean = statistics.stdev(data)
    
    # Calculate mean and provide it to stdev
    data_mean = statistics.mean(data)
    stdev_with_mean = statistics.stdev(data, data_mean)
    
    # Results should be approximately equal due to floating point arithmetic
    assert math.isclose(stdev_without_mean, stdev_with_mean, rel_tol=1e-9)

@given(
    center=st.floats(min_value=-1000, max_value=1000, allow_nan=False, allow_infinity=False),
    n_pairs=st.integers(min_value=1, max_value=20),
    offsets=st.lists(
        st.floats(min_value=0.1, max_value=100, allow_nan=False, allow_infinity=False),
        min_size=1,
        max_size=20
    )
)
def test_symmetric_unimodal_distribution_central_tendency_convergence(center, n_pairs, offsets):
    """
    Test that for symmetric unimodal distributions, mode â‰ˆ median â‰ˆ mean.
    
    This property holds for symmetric unimodal distributions where all three
    measures of central tendency should converge to approximately the same value.
    We generate symmetric data by creating values symmetrically around a center point.
    """
    import math
    from statistics import mean, median, mode
    
    # Take only n_pairs offsets to ensure we have the right number
    selected_offsets = offsets[:n_pairs]
    
    # Build symmetric dataset
    dataset = []
    for offset in selected_offsets:
        dataset.extend([center + offset, center - offset])
    
    # Add the center point multiple times to make it the clear mode
    # Use a fixed number to ensure unimodality without creating overly large datasets
    dataset.extend([center] * 5)
    
    try:
        sample_mean = mean(dataset)
        sample_median = median(dataset)
        sample_mode = mode(dataset)
        
        # For symmetric unimodal distributions, all measures should be approximately equal
        tolerance = 1e-6  # Use reasonable tolerance for floating-point arithmetic
        
        # Test that mean â‰ˆ median
        assert math.isclose(sample_mean, sample_median, rel_tol=tolerance, abs_tol=tolerance), \
            f"Mean ({sample_mean}) and median ({sample_median}) should be approximately equal for symmetric distribution"
        
        # Test that median â‰ˆ mode  
        assert math.isclose(sample_median, sample_mode, rel_tol=tolerance, abs_tol=tolerance), \
            f"Median ({sample_median}) and mode ({sample_mode}) should be approximately equal for symmetric distribution"
        
        # Test that mean â‰ˆ mode
        assert math.isclose(sample_mean, sample_mode, rel_tol=tolerance, abs_tol=tolerance), \
            f"Mean ({sample_mean}) and mode ({sample_mode}) should be approximately equal for symmetric distribution"
            
    except Exception as e:
        # Should not raise exceptions for valid symmetric data
        assert False, f"Unexpected exception with symmetric data: {e}"

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e100, max_value=1e100), min_size=2, max_size=100))
def test_variance_non_negative_and_zero_iff_all_equal(data):
    """
    Test that variance(data) >= 0, with equality if and only if all elements 
    in data are equal to mean(data). This means variance is zero only when
    all data points are identical.
    """
    import math
    from statistics import variance, mean
    
    var = variance(data)
    data_mean = mean(data)
    
    # Property 1: Variance is always non-negative
    assert var >= 0, f"Variance should be non-negative, got {var}"
    
    # Property 2: Variance equals zero if and only if all elements are equal to the mean
    # This happens when all data points are identical
    all_equal_to_mean = all(math.isclose(x, data_mean, rel_tol=1e-9, abs_tol=1e-9) for x in data)
    
    if all_equal_to_mean:
        # If all elements equal the mean, variance should be zero
        assert math.isclose(var, 0, abs_tol=1e-9), f"Variance should be zero when all elements equal mean, got {var}"
    else:
        # If not all elements equal the mean, variance should be positive
        assert var > 0, f"Variance should be positive when elements differ, got {var}"

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2, max_size=50))
def test_stdev_non_negative_and_zero_iff_constant(data):
    """
    Test that stdev(data) >= 0, with equality if and only if 
    all elements in data are equal to mean(data).
    
    This property verifies:
    1. Standard deviation is always non-negative
    2. Standard deviation is zero if and only if all data points equal the mean
       (i.e., all data points are identical)
    """
    import math
    from statistics import stdev, mean, StatisticsError
    
    # Use consistent tolerance throughout the test
    tolerance = 1e-9
    
    try:
        sample_stdev = stdev(data)
        sample_mean = mean(data)
        
        # Property 1: stdev(data) >= 0
        assert sample_stdev >= 0, f"Standard deviation should be non-negative, got {sample_stdev}"
        
        # Property 2: stdev(data) == 0 iff all elements equal mean(data)
        all_equal_to_mean = all(math.isclose(x, sample_mean, rel_tol=tolerance, abs_tol=tolerance) for x in data)
        stdev_is_zero = math.isclose(sample_stdev, 0, rel_tol=tolerance, abs_tol=tolerance)
        
        if stdev_is_zero:
            # If stdev is zero, all elements should equal the mean
            assert all_equal_to_mean, f"If stdev is zero, all elements should equal mean. Data: {data}, Mean: {sample_mean}"
        else:
            # If stdev is positive, not all elements should equal the mean
            assert not all_equal_to_mean, f"If stdev is positive, not all elements should equal mean. Data: {data}, Mean: {sample_mean}, Stdev: {sample_stdev}"
            
    except StatisticsError:
        # This should never happen since we generate at least 2 data points
        assert False, f"StatisticsError should not occur with {len(data)} data points: {data}"

@given(st.lists(st.just(5.0), min_size=2, max_size=10))
def test_stdev_zero_for_constant_data(constant_data):
    """
    Test that stdev returns exactly 0 for data where all elements are identical.
    This is a specific test case for the equality condition.
    """
    from statistics import stdev
    import math
    
    result = stdev(constant_data)
    assert math.isclose(result, 0, abs_tol=1e-10), f"Standard deviation of constant data should be 0, got {result}"

@given(st.tuples(st.integers(min_value=2, max_value=100), st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2).filter(lambda x: len(set(x)) > 1)))
def test_stdev_positive_for_varying_data(data_tuple):
    """
    Test that stdev returns a positive value when data elements are not all identical.
    This tests the strict inequality case.
    """
    from statistics import stdev
    
    n, data = data_tuple
    
    # Verify precondition: data actually varies
    assert len(set(data)) > 1, f"Test precondition failed: data should have varying elements, got {data}"
    
    sample_stdev = stdev(data)
    assert sample_stdev > 0, f"Standard deviation should be positive for varying data, got {sample_stdev} for data {data}"

@given(st.lists(st.integers(), min_size=1).filter(lambda x: len(set(x)) == len(x)))
def test_mode_with_no_repeated_values_returns_first_occurrence(data):
    """
    Test that when a dataset has no repeated values (all values appear exactly once),
    the mode function returns one of the values from the dataset.
    
    This tests that mode() behaves correctly when all frequencies are equal,
    returning a valid element from the original data.
    """
    from statistics import mode
    
    # All values in data are unique (enforced by filter)
    result = mode(data)
    
    # The result should be one of the values in the dataset
    assert result in data, f"Result {result} not found in original data {data}"

@given(st.lists(st.text(min_size=1), min_size=1).filter(lambda x: len(set(x)) == len(x)))
def test_mode_with_no_repeated_values_non_numeric_data(data):
    """
    Test that mode raises StatisticsError with non-numeric data when all values are unique.
    This ensures the property holds for nominal data as well as numeric data - when there
    is no unique mode (all values appear with equal frequency), StatisticsError is raised.
    """
    import pytest
    from statistics import mode, StatisticsError
    
    # All values in data are unique (enforced by filter)
    # mode() should raise StatisticsError when there is no unique mode
    with pytest.raises(StatisticsError):
        mode(data)

@given(st.lists(st.one_of(st.integers(), st.text(), st.floats(allow_nan=False, allow_infinity=False)), min_size=1).filter(lambda x: len(set(x)) == len(x)))
def test_mode_unique_values_mixed_types(data):
    """
    Test mode behavior with mixed data types when all values are unique.
    Verifies that the first-occurrence behavior is consistent across different data types.
    """
    from statistics import mode
    
    # Precondition: all values are unique (enforced by strategy filter)
    assert len(set(data)) == len(data), "Test precondition failed: values not unique"
    
    result = mode(data)
    
    # Should return the first element since all have frequency 1
    assert result == data[0], f"Expected first element {data[0]}, got {result}"

@given(
    constant=st.one_of(
        st.floats(allow_nan=False, allow_infinity=False),
        st.decimals(allow_nan=False, allow_infinity=False),
        st.fractions()
    ),
    n=st.integers(min_value=1, max_value=1000)
)
def test_constant_dataset_statistics_property(constant, n):
    """
    Test that for a dataset where all values are the same constant:
    - mean([constant] * n) = constant
    - variance([constant] * n) = 0  
    - stdev([constant] * n) = 0
    
    This property demonstrates how these statistical functions relate
    for datasets with no variation.
    """
    import math
    from decimal import Decimal
    from fractions import Fraction
    from statistics import mean, variance, stdev
    
    # Create dataset with all values equal to the constant
    data = [constant] * n
    
    # Test mean equals the constant
    calculated_mean = mean(data)
    if isinstance(constant, (Decimal, Fraction)):
        # For exact types, use exact equality
        assert calculated_mean == constant
    else:
        # For floats, use approximate equality
        assert math.isclose(calculated_mean, constant, rel_tol=1e-9, abs_tol=1e-9)
    
    # Test variance equals zero
    calculated_variance = variance(data)
    if isinstance(constant, (Decimal, Fraction)):
        # For exact types, variance should be exactly zero
        assert calculated_variance == 0
    else:
        # For floats, variance should be very close to zero
        assert math.isclose(calculated_variance, 0, rel_tol=1e-9, abs_tol=1e-9)
    
    # Test standard deviation equals zero
    calculated_stdev = stdev(data)
    if isinstance(constant, (Decimal, Fraction)):
        # For exact types, stdev should be exactly zero
        assert calculated_stdev == 0
    else:
        # For floats, stdev should be very close to zero
        assert math.isclose(calculated_stdev, 0, rel_tol=1e-9, abs_tol=1e-9)
    
    # Additional property: stdev should equal sqrt(variance)
    if isinstance(constant, (Decimal, Fraction)):
        assert calculated_stdev == 0 and calculated_variance == 0
    else:
        assert math.isclose(calculated_stdev, math.sqrt(calculated_variance), rel_tol=1e-9, abs_tol=1e-9)

@given(st.one_of(st.integers(), st.floats(allow_nan=False, allow_infinity=False), st.decimals(allow_nan=False, allow_infinity=False), st.fractions()))
def test_single_element_central_tendency_equality(x):
    """
    Test that for single-element datasets, mean, median, and mode all equal the single value.
    
    Property: For single-element datasets: mean([x]) = median([x]) = mode([x]) = x
    
    This tests that all three measures of central tendency are identical when there's
    only one data point, which must be true by mathematical definition.
    """
    from statistics import mean, median, mode
    import math
    from decimal import Decimal
    from fractions import Fraction
    
    single_element_data = [x]
    
    # Calculate all three measures of central tendency
    calculated_mean = mean(single_element_data)
    calculated_median = median(single_element_data)
    calculated_mode = mode(single_element_data)
    
    # For numeric types, we need to handle potential floating point precision issues
    if isinstance(x, float):
        # Use math.isclose for float comparisons
        assert math.isclose(calculated_mean, x, rel_tol=1e-15), f"mean([{x}]) = {calculated_mean}, expected {x}"
        assert math.isclose(calculated_median, x, rel_tol=1e-15), f"median([{x}]) = {calculated_median}, expected {x}"
        assert math.isclose(calculated_mode, x, rel_tol=1e-15), f"mode([{x}]) = {calculated_mode}, expected {x}"
        
        # Also check that all three measures are equal to each other
        assert math.isclose(calculated_mean, calculated_median, rel_tol=1e-15)
        assert math.isclose(calculated_median, calculated_mode, rel_tol=1e-15)
        assert math.isclose(calculated_mean, calculated_mode, rel_tol=1e-15)
    else:
        # For exact numeric types and non-numeric types, use exact equality
        assert calculated_mean == x, f"mean([{x}]) = {calculated_mean}, expected {x}"
        assert calculated_median == x, f"median([{x}]) = {calculated_median}, expected {x}"
        assert calculated_mode == x, f"mode([{x}]) = {calculated_mode}, expected {x}"
        
        # Also check that all three measures are equal to each other
        assert calculated_mean == calculated_median
        assert calculated_median == calculated_mode
        assert calculated_mean == calculated_mode