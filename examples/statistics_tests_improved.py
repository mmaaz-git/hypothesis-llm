"""Property-based tests for statistics module.
Generated by hypothesis-llm.
"""

import hypothesis
from hypothesis import given, strategies as st
from statistics import (
    mean,
    median,
    mode,
    stdev,
    variance
)



@given(st.lists(st.integers(), min_size=1))
def test_median_bounded_output(data):
    """Test that median is bounded by min and max of the data."""
    result = median(data)
    assert min(data) <= result <= max(data)



@given(st.integers())
def test_median_single_element_property(x):
    """Test that median of single element list equals that element."""
    result = median([x])
    assert result == x



@given(st.lists(st.integers(), min_size=1), st.integers())
def test_median_translation_invariant(data, c):
    """Test that median is translation invariant."""
    import math
    original_median = median(data)
    translated_data = [x + c for x in data]
    translated_median = median(translated_data)
    expected = original_median + c
    # Use math.isclose for float comparison in case of division
    assert math.isclose(translated_median, expected)



@given(st.integers())
def test_single_element_returns_that_element_integers(value):
    """Test that mode of single element list returns that element."""
    result = mode([value])
    assert result == value



@given(st.text())
def test_single_element_returns_that_element_strings(value):
    """Test that mode of single element list returns that element (strings)."""
    result = mode([value])
    assert result == value



@given(st.lists(st.integers(), min_size=1))
def test_duplicate_removal_equivalence(data):
    """Test that mode(data) gives same result as mode constructed from unique elements with counts."""
    from collections import Counter
    
    original_mode = mode(data)
    counter = Counter(data)
    
    # Reconstruct data from counter (unique elements with their counts)
    reconstructed_data = []
    for element, count in counter.items():
        reconstructed_data.extend([element] * count)
    
    reconstructed_mode = mode(reconstructed_data)
    assert original_mode == reconstructed_mode


@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2, max_size=20))
def test_stdev_non_negativity(data):
    """Test that standard deviation is always non-negative."""
    result = stdev(data)
    assert result >= 0



@given(st.floats(allow_nan=False, allow_infinity=False), st.integers(min_value=2, max_value=10))
def test_variance_zero_for_constant_data(value, size):
    """Test that variance is zero when all data points are identical."""
    import math
    data = [value] * size
    result = variance(data)
    assert math.isclose(result, 0, abs_tol=1e-10), f"Variance of constant data should be 0, got {result}"



@given(st.floats(allow_nan=False, allow_infinity=False))
def test_variance_single_element_duplication(x):
    """Test that variance([x, x]) == 0 for any x."""
    import math
    data = [x, x]
    result = variance(data)
    assert math.isclose(result, 0, abs_tol=1e-10), f"Variance of [x, x] should be 0, got {result}"



@given(st.lists(st.integers(min_value=-1000, max_value=1000), min_size=2, max_size=20))
def test_stdev_equals_sqrt_of_variance_integers(data):
    """Test that stdev(data) == sqrt(variance(data)) for integer data.
    
    This property tests the fundamental relationship between standard deviation
    and variance with integer inputs.
    """
    import math
    
    # Calculate both stdev and sqrt(variance)
    actual_stdev = stdev(data)
    actual_variance = variance(data)
    expected_stdev = math.sqrt(actual_variance)
    
    # Use math.isclose for floating point comparison
    assert math.isclose(actual_stdev, expected_stdev, rel_tol=1e-10)



@given(st.lists(st.fractions(min_value=-100, max_value=100), min_size=2, max_size=20))
def test_variance_with_explicit_mean_equals_variance_without_mean_fractions(data):
    """
    Test that variance(data, mean(data)) == variance(data) with Fraction data.
    
    This tests the property with Fraction objects to ensure exact arithmetic
    without floating point precision issues.
    """
    from statistics import variance, mean
    
    # Calculate variance without providing mean (automatic calculation)
    var_auto = variance(data)
    
    # Calculate mean explicitly and pass it to variance
    data_mean = mean(data)
    var_explicit = variance(data, data_mean)
    
    # With Fraction arithmetic, these should be exactly equal
    assert var_auto == var_explicit


@given(st.floats(allow_nan=False, allow_infinity=False), st.integers(min_value=2, max_value=100))
def test_identical_elements_zero_variance_and_stdev(value, length):
    """
    Test that for data with identical elements [x, x, ..., x]:
    - stdev(data) == 0 
    - variance(data) == 0
    
    This property holds because when all data points are identical, there is no 
    variation from the mean, so both standard deviation and variance should be zero.
    """
    import math
    
    # Create data with identical elements
    data = [value] * length
    
    # Calculate variance and standard deviation
    var_result = variance(data)
    stdev_result = stdev(data)
    
    # Both should be exactly zero for identical elements
    # Using math.isclose with tight tolerances to handle floating point precision
    assert math.isclose(var_result, 0, abs_tol=1e-15), f"variance({data}) = {var_result}, expected 0"
    assert math.isclose(stdev_result, 0, abs_tol=1e-15), f"stdev({data}) = {stdev_result}, expected 0"
    
    # Also test with explicit xbar parameter
    mean_value = value  # mean of identical elements is the element itself
    var_result_with_xbar = variance(data, mean_value)
    stdev_result_with_xbar = stdev(data, mean_value)
    
    assert math.isclose(var_result_with_xbar, 0, abs_tol=1e-15), f"variance({data}, {mean_value}) = {var_result_with_xbar}, expected 0"
    assert math.isclose(stdev_result_with_xbar, 0, abs_tol=1e-15), f"stdev({data}, {mean_value}) = {stdev_result_with_xbar}, expected 0"

@given(st.just([]))
def test_empty_input_raises_statistics_error(data):
    """Test that empty input raises StatisticsError."""
    import pytest
    from statistics import StatisticsError
    with pytest.raises(StatisticsError):
        mean(data)

import math

@given(st.one_of(st.integers(), st.floats(allow_nan=False, allow_infinity=False)))
def test_single_element_mean_equals_element(x):
    """Test that mean of single element equals the element itself."""
    result = mean([x])
    if isinstance(x, float):
        assert math.isclose(result, x)
    else:
        assert result == x

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1, max_size=20))
def test_mean_bounded_by_min_max(data):
    """Test that mean is bounded by minimum and maximum values.
    
    The mean of any list of numbers must always be between (or equal to) 
    the minimum and maximum values in that list. This is a fundamental 
    mathematical property that should hold exactly for any correct mean 
    implementation.
    """
    result = mean(data)
    min_val = min(data)
    max_val = max(data)
    
    # The mean should always be mathematically between min and max
    assert min_val <= result <= max_val

import math

@given(st.lists(st.integers(), min_size=1, max_size=10))
def test_mean_preserves_numeric_type_consistency_integers(data):
    """Test that mean returns appropriate numeric type and correct value for integer inputs.
    
    For integer inputs, the mean should:
    1. Always return a numeric type (int or float)
    2. Return the mathematically correct result
    3. Return an int only if the sum is perfectly divisible by length, float otherwise
    """
    result = mean(data)
    
    # Result should be numeric (int or float)
    assert isinstance(result, (int, float))
    
    # Calculate expected result
    expected = sum(data) / len(data)
    
    # The result should be mathematically correct
    if isinstance(result, float) and isinstance(expected, float):
        assert math.isclose(result, expected, rel_tol=1e-10)
    else:
        assert result == expected
    
    # Test type consistency: if sum is perfectly divisible by length,
    # the result could be int or float, but should be mathematically equivalent
    total = sum(data)
    length = len(data)
    if total % length == 0:
        # Perfect division - result should equal the integer quotient
        expected_int = total // length
        if isinstance(result, int):
            assert result == expected_int
        else:  # result is float
            assert math.isclose(result, float(expected_int), rel_tol=1e-10)
    else:
        # Non-perfect division - result should be a float (in most implementations)
        # But we primarily care that it's mathematically correct
        assert math.isclose(result, total / length, rel_tol=1e-10)

import math

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1, max_size=10))
def test_mean_preserves_numeric_type_consistency_floats(data):
    """Test that mean preserves numeric type consistency for floats.
    
    When given a list of floats, the mean function should return a float,
    preserving the input type consistency.
    """
    result = mean(data)
    # Result should specifically be a float to preserve type consistency
    assert isinstance(result, float), f"Expected float, got {type(result)}"
    # Additionally verify the result is a valid number
    assert not math.isnan(result), "Mean should not return NaN for valid float inputs"
    assert not math.isinf(result), "Mean should not return infinity for finite float inputs"

import math

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1000, max_value=1000), min_size=1, max_size=10),
       st.floats(allow_nan=False, allow_infinity=False, min_value=-10, max_value=10))
def test_scaling_property(data, k):
    """Test scaling property: mean([k*x for x in data]) == k * mean(data).
    
    This property tests that scaling all elements in a dataset by a constant k
    should result in the mean being scaled by the same constant k. This is a
    fundamental mathematical property of the arithmetic mean.
    """
    scaled_data = [k * x for x in data]
    original_mean = mean(data)
    scaled_mean = mean(scaled_data)
    expected = k * original_mean
    
    assert math.isclose(scaled_mean, expected, rel_tol=1e-6, abs_tol=1e-9)

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1000, max_value=1000), min_size=1, max_size=10),
       st.floats(allow_nan=False, allow_infinity=False, min_value=-10, max_value=10))
def test_translation_property(data, k):
    """Test translation property: mean([x + k for x in data]) == mean(data) + k."""
    import math
    translated_data = [x + k for x in data]
    original_mean = mean(data)
    translated_mean = mean(translated_data)
    expected = original_mean + k
    
    assert math.isclose(translated_mean, expected, rel_tol=1e-9)

import math

@given(st.one_of(st.floats(allow_nan=False, allow_infinity=False), st.integers()), st.integers(min_value=1, max_value=20))
def test_constant_dataset_property(c, n):
    """Test constant dataset property: mean([c, c, ..., c]) == c.
    
    This property should hold for any constant value c (float or integer)
    repeated n times in a dataset. The mean of identical values should
    equal that value.
    """
    data = [c] * n
    result = mean(data)
    
    if isinstance(c, float):
        assert math.isclose(result, c)
    else:
        assert result == c

import math

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e100, max_value=1e100), min_size=1, max_size=10),
       st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e100, max_value=1e100), min_size=1, max_size=10))
def test_addition_property(data1, data2):
    """Test addition property: mean(data1 + data2) relates to mean(data1) and mean(data2).
    
    This test verifies that when two datasets are concatenated, the mean of the combined
    dataset equals the weighted average of the individual means, where weights are the
    sizes of the original datasets.
    
    Mathematical property: mean(data1 + data2) = (n1*mean1 + n2*mean2) / (n1 + n2)
    where n1, n2 are the sizes of data1, data2 respectively.
    """
    combined_data = data1 + data2
    mean1 = mean(data1)
    mean2 = mean(data2)
    combined_mean = mean(combined_data)
    
    # The weighted average formula: (n1*mean1 + n2*mean2) / (n1 + n2)
    n1, n2 = len(data1), len(data2)
    expected = (n1 * mean1 + n2 * mean2) / (n1 + n2)
    
    # Use more lenient tolerance to account for floating-point arithmetic limitations
    # with large numbers and multiple operations
    assert math.isclose(combined_mean, expected, rel_tol=1e-6, abs_tol=1e-9)

import math
from hypothesis import given, strategies as st

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1, max_size=20))
def test_order_independence(data):
    """Test order independence: mean(data) == mean(shuffled(data)).
    
    The mean of a dataset should be invariant under permutations of the data.
    This property tests that our mean function produces the same result
    regardless of the order of input elements.
    """
    original_mean = mean(data)
    
    # Use Hypothesis's built-in shuffling for deterministic, reproducible tests
    # We can create a permutation by sorting with a generated key
    shuffled_data = sorted(data, key=lambda x: hash((x, len(data))))
    
    # If that gives us the same order, reverse it to ensure we test a different order
    if shuffled_data == data:
        shuffled_data = list(reversed(data))
    
    shuffled_mean = mean(shuffled_data)
    
    # Use math.isclose for robust floating-point comparison
    assert math.isclose(original_mean, shuffled_mean, rel_tol=1e-9)

from statistics import StatisticsError, median
import pytest
from hypothesis import given, strategies as st

@given(st.one_of(st.just([]), st.just(()), st.just(iter([]))))
def test_median_empty_sequence_raises_error(empty_seq):
    """Test that median raises StatisticsError for any empty sequence.
    
    This property-based test verifies that the median function correctly
    raises StatisticsError when given empty sequences of different types
    (list, tuple, iterator).
    """
    with pytest.raises(StatisticsError):
        median(empty_seq)

@given(st.lists(st.integers(), min_size=1).filter(lambda x: len(x) % 2 == 1))
def test_median_odd_length_invariant(data):
    """Test that for odd length data, median equals the middle element of sorted data."""
    result = median(data)
    sorted_data = sorted(data)
    expected_median = sorted_data[len(sorted_data) // 2]
    assert result == expected_median

import math

@given(st.lists(st.integers(), min_size=2).filter(lambda x: len(x) % 2 == 0))
def test_median_even_length_interpolation(data):
    """Test that for even length data, median is average of two middle elements."""
    result = median(data)
    sorted_data = sorted(data)
    n = len(sorted_data)
    expected = (sorted_data[n // 2 - 1] + sorted_data[n // 2]) / 2
    assert math.isclose(result, expected)

@given(st.lists(st.integers(), min_size=1).flatmap(
    lambda data: st.tuples(st.just(data), st.permutations(data))
))
def test_median_permutation_invariant(data_and_shuffled):
    """Test that median is invariant under permutation of data."""
    data, shuffled_data = data_and_shuffled
    original_median = median(data)
    shuffled_median = median(list(shuffled_data))
    assert original_median == shuffled_median

@given(st.integers(min_value=-(2**53), max_value=2**53), st.integers(min_value=1, max_value=100))
def test_median_duplicate_preservation(x, count):
    """Test that median of list with all identical elements equals that element.
    
    This property tests that when all elements in a list are identical,
    the median should be exactly that element. We limit the integer range
    to -(2^53) to 2^53 to ensure exact representation in floating-point
    arithmetic and avoid precision issues.
    """
    data = [x] * count
    result = median(data)
    assert result == x

import math

@given(st.integers(), st.integers())
def test_median_two_element_property(a, b):
    """Test that median of two elements equals their average."""
    result = median([a, b])
    expected = (a + b) / 2
    assert math.isclose(result, expected)

@given(st.lists(st.integers(), min_size=1), st.integers(min_value=1, max_value=100))
def test_median_monotonicity_under_scaling(data, k):
    """Test that median scales linearly with positive scaling factor."""
    import math
    
    original_median = median(data)
    scaled_data = [k * x for x in data]
    scaled_median = median(scaled_data)
    expected = k * original_median
    
    # For integer data and scaling, result should be exact unless median is a float
    # (which happens when list has even length and middle two elements differ)
    if isinstance(original_median, int):
        # When original median is integer, scaled result should also be exact integer
        assert scaled_median == expected
    else:
        # When original median is float (even-length list), use floating-point comparison
        # Both scaled_median and expected should be floats with exact fractional parts
        # since we're scaling integer data by integer factor
        assert math.isclose(scaled_median, expected)

import pytest
from statistics import StatisticsError, mode

@given(st.just([]))
def test_empty_data_raises_statistics_error(data):
    """Test that empty data raises StatisticsError."""
    with pytest.raises(StatisticsError, match=r".*empty.*"):
        mode(data)

from collections import Counter

@given(st.lists(st.integers(), min_size=1))
def test_mode_returns_most_frequent_element(data):
    """Test that the mode returns an element with the highest frequency."""
    result = mode(data)
    
    # The result should be in the input data
    assert result in data
    
    # The result should have the maximum frequency
    counts = Counter(data)
    max_count = max(counts.values())
    assert counts[result] == max_count

@given(st.lists(st.sampled_from(['a', 'b', 'c', 'd']), min_size=1).flatmap(
    lambda lst: st.lists(st.sampled_from(lst), min_size=len(lst) + 5)
))
def test_output_is_element_from_input_data_strings(data):
    """
    Test that the mode is always an element that exists in the input data (strings)
    and that it actually has the highest frequency among all elements.
    
    The strategy ensures duplicates exist by:
    1. First generating a list of strings from a small alphabet
    2. Then creating a larger list by sampling from the first list
    This guarantees that some elements will appear multiple times.
    """
    result = mode(data)
    
    # Test that result is actually in the input data
    assert result in data
    
    # Test that the result actually has the highest frequency (is truly the mode)
    result_count = data.count(result)
    max_count = max(data.count(x) for x in set(data))
    assert result_count == max_count, f"Result '{result}' appears {result_count} times, but max frequency is {max_count}"

@given(st.lists(st.integers(), min_size=1))
def test_result_has_maximum_frequency(data):
    """Test that the mode has the maximum frequency in the data and is actually present in the data."""
    from collections import Counter
    
    result = mode(data)
    counter = Counter(data)
    
    # Ensure the result is actually in the original data
    assert result in data, f"Mode result {result} not found in original data {data}"
    
    # Ensure the result has maximum frequency
    result_frequency = counter[result]
    max_frequency = max(counter.values())
    assert result_frequency == max_frequency, f"Result frequency {result_frequency} != max frequency {max_frequency}"
    
    # Additional check: ensure no value has higher frequency than the result
    for value, freq in counter.items():
        assert freq <= result_frequency, f"Value {value} has frequency {freq} > result frequency {result_frequency}"

from hypothesis import assume
from collections import Counter

@given(
    st.integers(),
    st.integers(),
    st.lists(st.integers()).map(lambda lst: lst[:100])  # Limit size for performance
)
def test_first_occurrence_tie_breaking(first_tied, second_tied, other_data):
    """Test that when there are ties, the first occurrence in order is returned."""
    # Ensure the two tied values are different
    assume(first_tied != second_tied)
    
    # Filter other_data to exclude the tied values to ensure clean tie conditions
    other_data = [x for x in other_data if x not in [first_tied, second_tied]]
    
    # Ensure no element in other_data appears more than once to guarantee
    # that first_tied and second_tied will be tied for maximum frequency
    other_data_counts = Counter(other_data)
    other_data = [x for x, count in other_data_counts.items() if count == 1]
    
    # Create data where first_tied and second_tied both appear exactly twice
    # and first_tied appears before second_tied in the first occurrence
    data = [first_tied, second_tied, first_tied, second_tied] + other_data
    
    result = mode(data)
    counter = Counter(data)
    
    # Verify our test setup: both tied values should have frequency 2
    # and this should be the maximum frequency (since other elements appear at most once)
    assert counter[first_tied] == 2
    assert counter[second_tied] == 2
    assert max(counter.values()) == 2
    
    # The key property: when tied for maximum frequency, 
    # the first occurrence in order should be returned
    assert result == first_tied

from collections import Counter

@given(st.lists(st.one_of(st.integers(), st.text(), st.tuples(st.integers())), min_size=1))
def test_works_with_hashable_data_types(data):
    """Test that mode works with various hashable data types and returns the most frequent element."""
    result = mode(data)
    
    # The result should be in the input data
    assert result in data
    
    # The result should be one of the most frequent elements
    counter = Counter(data)
    max_count = max(counter.values())
    most_frequent_elements = [elem for elem, count in counter.items() if count == max_count]
    
    # The mode function should return one of the elements with maximum frequency
    assert result in most_frequent_elements
    
    # Verify that no other element appears more frequently than the result
    result_count = counter[result]
    for element, count in counter.items():
        assert count <= result_count, f"Element {element} appears {count} times, but mode {result} appears only {result_count} times"

@given(st.lists(st.integers(), min_size=1).flatmap(lambda x: st.tuples(st.just(x), st.permutations(x))))
def test_order_independence_for_non_tied_cases(data_and_permutation):
    """Test that for non-tied cases, order doesn't affect the result.
    
    This property test verifies that when there are no ties (i.e., only one element
    has the maximum frequency), the mode function returns the same result regardless
    of the order of elements in the input list. This tests the fundamental property
    that mode should be order-independent when there's a clear winner.
    """
    from collections import Counter
    
    original_data, permuted_data = data_and_permutation
    
    # Convert permuted_data (which is a tuple from st.permutations) to a list
    permuted_list = list(permuted_data)
    
    counter = Counter(original_data)
    
    # Check if there are ties for the maximum frequency
    max_freq = max(counter.values())
    elements_with_max_freq = [elem for elem, freq in counter.items() if freq == max_freq]
    
    # Only test order independence if there's no tie (exactly one element with max frequency)
    if len(elements_with_max_freq) == 1:
        original_mode = mode(original_data)
        permuted_mode = mode(permuted_list)
        
        # For non-tied cases, both permutations should return the same mode
        assert original_mode == permuted_mode, f"Mode should be order-independent for non-tied cases. Original: {original_mode}, Permuted: {permuted_mode}"

@given(st.floats(allow_nan=False, allow_infinity=False), st.integers(min_value=2, max_value=10))
def test_stdev_zero_for_identical_values(value, size):
    """Test that standard deviation is zero for identical values.
    
    This property tests that when all values in a dataset are identical,
    the standard deviation should be zero. We use both relative and absolute
    tolerance to handle floating-point precision errors that can accumulate
    during computation, especially for very large or very small numbers.
    """
    import math
    data = [value] * size
    result = stdev(data)
    assert math.isclose(result, 0, rel_tol=1e-9, abs_tol=1e-9)

from statistics import StatisticsError

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=0, max_size=1))
def test_stdev_error_for_insufficient_data(data):
    """Test that stdev raises StatisticsError when data has fewer than 2 points (0 or 1 elements)."""
    import pytest
    with pytest.raises(StatisticsError):
        stdev(data)

import math
from statistics import stdev

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6), min_size=2, max_size=10),
       st.floats(allow_nan=False, allow_infinity=False, min_value=0.1, max_value=10))
def test_stdev_scale_invariance(data, k):
    """Test that stdev([k*x for x in data]) == k * stdev(data) for k > 0.
    
    This property tests the scale invariance of standard deviation:
    - When all values in a dataset are multiplied by a positive constant k,
      the standard deviation should also be multiplied by k.
    - Special case: if the original data has zero standard deviation (constant values),
      the scaled data should also have zero standard deviation.
    """
    scaled_data = [k * x for x in data]
    original_stdev = stdev(data)
    scaled_stdev = stdev(scaled_data)
    
    if original_stdev == 0:
        # If original data has zero standard deviation (constant values), 
        # scaled data should also have zero standard deviation
        assert scaled_stdev == 0
    else:
        expected = k * original_stdev
        # Use a more reasonable tolerance to account for floating-point precision errors
        assert math.isclose(scaled_stdev, expected, rel_tol=1e-9)

import math

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6), min_size=2, max_size=10),
       st.floats(allow_nan=False, allow_infinity=False, min_value=-1e4, max_value=1e4))
def test_stdev_translation_invariance(data, k):
    """Test that stdev([x + k for x in data]) == stdev(data).
    
    Translation invariance property: adding a constant to all values
    should not change the standard deviation, since standard deviation
    measures spread around the mean, and translation shifts both the
    data points and the mean by the same amount.
    """
    translated_data = [x + k for x in data]
    original_stdev = stdev(data)
    translated_stdev = stdev(translated_data)
    assert math.isclose(translated_stdev, original_stdev, rel_tol=1e-9, abs_tol=1e-12)

import math
import pytest

@given(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6),
       st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6))
def test_stdev_single_deviation_case(a, b):
    """Test that stdev([a, b]) matches the correct mathematical formula.
    
    For sample standard deviation (n-1): stdev([a, b]) = abs(a - b)
    For population standard deviation (n): stdev([a, b]) = abs(a - b) / sqrt(2)
    
    This test determines which formula the stdev function uses by testing
    with known values first, then applies the correct formula.
    """
    # First determine if stdev uses sample (n-1) or population (n) formula
    # Test with known values: [0, 1]
    test_data = [0.0, 1.0]
    test_result = stdev(test_data)
    
    # Sample standard deviation: sqrt((0-0.5)^2 + (1-0.5)^2) / sqrt(1) = sqrt(0.5) = 1.0
    # Population standard deviation: sqrt((0-0.5)^2 + (1-0.5)^2) / sqrt(2) = sqrt(0.25) ≈ 0.707
    
    is_sample_stdev = math.isclose(test_result, 1.0, rel_tol=1e-10)
    is_population_stdev = math.isclose(test_result, math.sqrt(0.5), rel_tol=1e-10)
    
    assert is_sample_stdev or is_population_stdev, f"stdev function uses unknown formula, got {test_result}"
    
    # Now test with the provided values using the correct formula
    data = [a, b]
    result = stdev(data)
    
    if is_sample_stdev:
        # Sample standard deviation: for n=2, stdev = abs(a - b) / sqrt(1) = abs(a - b)
        expected = abs(a - b)
    else:
        # Population standard deviation: stdev = abs(a - b) / sqrt(2)
        expected = abs(a - b) / math.sqrt(2)
    
    assert math.isclose(result, expected, rel_tol=1e-9), f"Expected {expected}, got {result}"
    
    # Test edge case where a == b (should always result in 0)
    if math.isclose(a, b, rel_tol=1e-10):
        assert math.isclose(result, 0.0, abs_tol=1e-10), f"Standard deviation should be 0 when values are equal"

import math
from statistics import mean

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6), min_size=2, max_size=10))
def test_stdev_with_xbar_parameter(data):
    """Test that stdev with xbar parameter calculates standard deviation correctly.
    
    When providing the mean via the xbar parameter, the result should match
    the mathematical definition of sample standard deviation using that mean.
    """
    data_mean = mean(data)
    result_with_xbar = stdev(data, xbar=data_mean)
    
    # Manually calculate standard deviation using the same mean to verify
    # Sample standard deviation formula: sqrt(sum((x - mean)^2) / (n - 1))
    variance = sum((x - data_mean) ** 2 for x in data) / (len(data) - 1)
    expected_stdev = math.sqrt(variance)
    
    assert math.isclose(result_with_xbar, expected_stdev, rel_tol=1e-10)

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6), min_size=2, max_size=10))
def test_stdev_bounded_by_range(data):
    """Test that stdev(data) <= max(data) - min(data).
    
    The standard deviation measures the spread of data points around the mean.
    It is mathematically bounded by the range of the data, since the maximum
    possible deviation occurs when all points are at the extremes.
    """
    result = stdev(data)
    data_range = max(data) - min(data)
    assert result <= data_range + 1e-10  # Small tolerance for floating point precision

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6), min_size=2, max_size=10))
def test_stdev_relationship_to_variance(data):
    """Test that stdev(data)² approximates variance(data) for same data."""
    import math
    from statistics import variance, stdev
    
    stdev_result = stdev(data)
    variance_result = variance(data)
    stdev_squared = stdev_result ** 2
    
    assert math.isclose(stdev_squared, variance_result, rel_tol=1e-10)

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e10, max_value=1e10), min_size=2, max_size=20))
def test_variance_non_negative_output(data):
    """Test that variance always returns a non-negative value for valid data.
    
    This test verifies the mathematical property that variance is always non-negative
    since it represents the average of squared deviations from the mean.
    The floating-point range is constrained to prevent numerical precision issues
    that can occur with extremely large values (e.g., around 10^154) where
    floating-point arithmetic loses precision during variance calculations.
    """
    result = variance(data)
    assert result >= 0, f"Variance should be non-negative, got {result}"

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e10, max_value=1e10), min_size=2, max_size=20))
def test_variance_equivalence_with_explicit_mean(data):
    """Test that variance(data) == variance(data, mean(data)).
    
    This property tests that computing variance without providing a mean
    should be equivalent to computing variance with the explicitly calculated mean.
    The test restricts float values to a reasonable range to avoid floating-point
    precision issues that can occur with extremely large numbers.
    """
    import math
    from statistics import mean
    
    var_without_mean = variance(data)
    data_mean = mean(data)
    var_with_mean = variance(data, data_mean)
    
    assert math.isclose(var_without_mean, var_with_mean, rel_tol=1e-9), \
        f"variance(data) = {var_without_mean} should equal variance(data, mean) = {var_with_mean}"

import pytest
from statistics import StatisticsError

@given(st.just([]))
def test_variance_error_condition_empty_data(data):
    """Test that variance raises StatisticsError when data is empty (0 points)."""
    with pytest.raises(StatisticsError, match="variance requires at least two data points"):
        variance(data)

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1, max_size=1))
def test_variance_error_condition_single_data_point(data):
    """Test that variance raises StatisticsError when data has exactly 1 point."""
    with pytest.raises(StatisticsError, match="variance requires at least two data points"):
        variance(data)

import math

@given(
    st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-100, max_value=100), 
             min_size=2, max_size=10),
    st.floats(allow_nan=False, allow_infinity=False, min_value=-10, max_value=10).filter(lambda x: x != 0)
)
def test_variance_scale_invariance(data, k):
    """Test that variance([k*x for x in data]) == k²*variance(data).
    
    This property tests the scale invariance of variance: when all data points
    are multiplied by a constant k, the variance should be multiplied by k².
    This is a fundamental mathematical property of variance.
    """
    
    original_var = variance(data)
    scaled_data = [k * x for x in data]
    scaled_var = variance(scaled_data)
    expected_var = k * k * original_var
    
    # Use more reasonable tolerances for floating-point comparisons
    # rel_tol=1e-9 accounts for accumulated rounding errors in variance calculations
    # abs_tol=1e-12 handles cases where expected_var is very close to zero
    assert math.isclose(scaled_var, expected_var, rel_tol=1e-9, abs_tol=1e-12), \
        f"Scaled variance {scaled_var} should equal k²*original_var = {expected_var}"

import math

@given(
    st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e10, max_value=1e10), min_size=2, max_size=10),
    st.floats(allow_nan=False, allow_infinity=False, min_value=-100, max_value=100)
)
def test_variance_translation_invariance(data, c):
    """Test that variance([x + c for x in data]) == variance(data).
    
    This property tests that variance is translation invariant - adding a constant
    to all values in a dataset should not change the variance. This is because
    variance measures spread around the mean, and translation shifts both the
    data points and the mean by the same amount.
    
    The floating point ranges are restricted to avoid numerical precision issues
    that can occur with extremely large values (e.g., >1e100) where floating
    point arithmetic becomes unstable.
    """
    original_var = variance(data)
    translated_data = [x + c for x in data]
    translated_var = variance(translated_data)
    
    assert math.isclose(original_var, translated_var, rel_tol=1e-10), \
        f"Translated variance {translated_var} should equal original variance {original_var}"

import math

@given(st.lists(st.integers(min_value=-100, max_value=100), min_size=2, max_size=10))
def test_variance_returns_float_for_integers(data):
    """Test that variance returns float for integer data and is non-negative."""
    result = variance(data)
    
    # For integer inputs, variance should return a float due to division operations
    assert isinstance(result, float), f"Expected float type for integer input, got {type(result)}"
    
    # Basic sanity check: variance should be non-negative
    assert result >= 0, f"Variance should be non-negative, got {result}"
    
    # Additional sanity check: variance should be finite
    assert math.isfinite(result), f"Variance should be finite, got {result}"
    
    # For constant data, variance should be 0
    if len(set(data)) == 1:
        assert math.isclose(result, 0.0), f"Variance of constant data should be 0, got {result}"

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e50, max_value=1e50), min_size=2, max_size=10))
def test_variance_permutation_invariance(data):
    """Test that variance is the same regardless of data order."""
    import math
    import random
    
    original_var = variance(data)
    permuted_data = data.copy()
    random.shuffle(permuted_data)
    permuted_var = variance(permuted_data)
    
    # Use more lenient tolerance to account for floating-point precision issues
    # with large numbers and accumulated rounding errors in variance calculations
    assert math.isclose(original_var, permuted_var, rel_tol=1e-9, abs_tol=1e-15), \
        f"Permuted variance {permuted_var} should equal original variance {original_var}"

import math

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2, max_size=10))
def test_variance_with_correct_mean(data):
    """Test that variance with correct mean produces mathematically correct result."""
    correct_mean = sum(data) / len(data)
    result = variance(data, correct_mean)
    expected = sum((x - correct_mean) ** 2 for x in data) / len(data)
    assert math.isclose(result, expected, rel_tol=1e-9), f"Expected {expected}, got {result}"

@given(
    st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2, max_size=10),
    st.floats(allow_nan=False, allow_infinity=False)
)
def test_variance_with_arbitrary_mean_behavior(data, provided_mean):
    """Test that variance computes correctly relative to any provided mean."""
    # Test that it computes variance relative to the provided mean
    # This is mathematically valid - variance can be computed relative to any reference point
    result = variance(data, provided_mean)
    expected = sum((x - provided_mean) ** 2 for x in data) / len(data)
    assert math.isclose(result, expected, rel_tol=1e-9), f"Expected {expected}, got {result}"
    assert isinstance(result, (int, float)), f"Expected numeric result, got {type(result)}"
    assert result >= 0, f"Variance should be non-negative, got {result}"

import statistics
from decimal import Decimal
import math

@given(st.lists(st.decimals(allow_nan=False, allow_infinity=False, min_value=-1000, max_value=1000, places=2), min_size=2, max_size=5))
def test_variance_decimal_support(data):
    """Test that variance works with Decimal types and produces correct results.
    
    This test verifies:
    1. Type preservation - result should be Decimal when input is Decimal
    2. Non-negativity - variance must be >= 0
    3. Correctness - result should match reference implementation within tolerance
    """
    result = variance(data)
    
    # Test type preservation
    assert isinstance(result, Decimal), f"Expected Decimal result for Decimal input, got {type(result)}"
    
    # Test non-negativity property
    assert result >= 0, f"Decimal variance should be non-negative, got {result}"
    
    # Test correctness by comparing with reference implementation
    # Convert to float for statistics.variance comparison, then back to Decimal for comparison
    float_data = [float(x) for x in data]
    expected = Decimal(str(statistics.variance(float_data)))
    
    # Use relative tolerance for comparison to handle different magnitudes
    tolerance = Decimal('0.01')
    if expected == 0:
        # For zero variance, use absolute tolerance
        assert abs(result - expected) <= tolerance, f"Variance calculation incorrect: got {result}, expected {expected}"
    else:
        # For non-zero variance, use relative tolerance
        relative_error = abs(result - expected) / expected
        assert relative_error <= tolerance, f"Variance calculation incorrect: got {result}, expected {expected}, relative error {relative_error}"

@given(st.lists(st.fractions(), min_size=2, max_size=5))
def test_variance_fraction_support(data):
    """Test that variance works with Fraction types and maintains precision."""
    from fractions import Fraction
    
    result = variance(data)
    
    # Check return type - should maintain Fraction precision
    assert isinstance(result, Fraction), f"Expected Fraction result for Fraction input, got {type(result)}"
    
    # Check non-negativity property
    assert result >= 0, f"Variance should be non-negative, got {result}"
    
    # For identical values, variance should be exactly 0
    if len(set(data)) == 1:
        assert result == Fraction(0), f"Variance of identical values should be exactly 0, got {result}"
        return
    
    # Verify correctness by computing variance manually using Fraction arithmetic
    n = len(data)
    mean = sum(data, Fraction(0)) / n  # Use Fraction(0) to maintain precision
    
    # Calculate sample variance (n-1 denominator) - most common definition
    expected_variance = sum((x - mean) ** 2 for x in data) / (n - 1)
    
    assert result == expected_variance, (
        f"Variance calculation incorrect for data {data}: "
        f"expected {expected_variance}, got {result}"
    )
    
    # Additional check: verify that we're maintaining exact fraction arithmetic
    # rather than converting to float at any point
    assert expected_variance.denominator > 0, "Expected variance should be a valid fraction"
    assert result.denominator > 0, "Result should be a valid fraction"

import math

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6).filter(lambda x: abs(x) > 1e-100 or x == 0.0), min_size=2, max_size=50))
def test_stdev_equals_sqrt_of_variance_floats(data):
    """Test that stdev(data) == sqrt(variance(data)) for float data.
    
    This property tests the fundamental relationship between standard deviation
    and variance: standard deviation is the square root of variance.
    
    The test filters out extremely small numbers (except exact 0.0) to avoid
    floating-point precision issues at the limits of representable numbers.
    """
    
    # Calculate both stdev and sqrt(variance)
    actual_stdev = stdev(data)
    actual_variance = variance(data)
    expected_stdev = math.sqrt(actual_variance)
    
    # Use math.isclose with relaxed tolerance for floating point comparison
    # rel_tol=1e-9 handles relative precision issues
    # abs_tol=1e-15 handles cases where both values are very close to zero
    assert math.isclose(actual_stdev, expected_stdev, rel_tol=1e-9, abs_tol=1e-15)

import math
import statistics

@given(
    st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6), min_size=2, max_size=20)
)
def test_stdev_equals_sqrt_of_variance_with_actual_mean(data):
    """Test that stdev(data, xbar) == sqrt(variance(data, xbar)) when xbar is the actual mean.
    
    This property tests the fundamental relationship between standard deviation
    and variance when the actual mean of the data is provided as xbar to both functions.
    This ensures we're testing the proper statistical relationship with meaningful values.
    """
    # Calculate the actual mean of the data
    xbar = statistics.mean(data)
    
    # Calculate both stdev and sqrt(variance) with the actual mean
    actual_stdev = stdev(data, xbar)
    actual_variance = variance(data, xbar)
    expected_stdev = math.sqrt(actual_variance)
    
    # Use math.isclose for floating point comparison
    assert math.isclose(actual_stdev, expected_stdev, rel_tol=1e-10)


@given(
    st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e6, max_value=1e6), min_size=2, max_size=20)
)
def test_stdev_equals_sqrt_of_variance_no_xbar(data):
    """Test that stdev(data) == sqrt(variance(data)) when no xbar is provided.
    
    This property tests the fundamental relationship between standard deviation
    and variance when both functions compute their own means internally.
    This validates that both functions use consistent mean calculations.
    """
    # Calculate both stdev and sqrt(variance) without providing xbar
    actual_stdev = stdev(data)
    actual_variance = variance(data)
    expected_stdev = math.sqrt(actual_variance)
    
    # Use math.isclose for floating point comparison
    assert math.isclose(actual_stdev, expected_stdev, rel_tol=1e-10)

from decimal import Decimal

@given(st.lists(st.decimals(min_value=-1000, max_value=1000, allow_nan=False, allow_infinity=False), min_size=2, max_size=10))
def test_stdev_equals_sqrt_of_variance_decimals(data):
    """Test that stdev(data) == sqrt(variance(data)) for Decimal data.
    
    This property tests the fundamental relationship between standard deviation
    and variance with Decimal inputs for higher precision arithmetic.
    """
    
    # Calculate both stdev and sqrt(variance)
    actual_stdev = stdev(data)
    actual_variance = variance(data)
    
    # Use Decimal sqrt to maintain precision
    expected_stdev = actual_variance.sqrt()
    
    # Compare using relative tolerance appropriate for Decimal precision
    tolerance = Decimal('1e-25')  # Much tighter tolerance for Decimal
    diff = abs(actual_stdev - expected_stdev)
    relative_error = diff / max(abs(actual_stdev), abs(expected_stdev), tolerance)
    
    assert relative_error <= tolerance

@given(st.lists(st.fractions(min_value=-100, max_value=100), min_size=2, max_size=10))
def test_stdev_equals_sqrt_of_variance_fractions(data):
    """Test that stdev(data) == sqrt(variance(data)) for Fraction data.
    
    This property tests the fundamental relationship between standard deviation
    and variance with Fraction inputs for exact rational arithmetic.
    """
    from fractions import Fraction
    from decimal import Decimal, getcontext
    
    # Set high precision for Decimal calculations
    getcontext().prec = 50
    
    # Calculate both stdev and variance
    actual_stdev = stdev(data)
    actual_variance = variance(data)
    
    # Ensure variance is non-negative (it should be by definition)
    assert actual_variance >= 0, "Variance should be non-negative"
    
    # Convert variance to Decimal and take square root for exact comparison
    variance_decimal = Decimal(str(actual_variance))
    expected_stdev = variance_decimal.sqrt()
    
    # Convert actual stdev to Decimal for comparison
    actual_stdev_decimal = Decimal(str(actual_stdev))
    
    # Compare using exact decimal arithmetic with high precision tolerance
    assert abs(actual_stdev_decimal - expected_stdev) < Decimal('1e-40'), \
        f"Standard deviation {actual_stdev_decimal} does not equal sqrt of variance {expected_stdev}"

import math

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e100, max_value=1e100), min_size=2, max_size=100))
def test_variance_with_explicit_mean_equals_variance_without_mean(data):
    """
    Test that variance(data, mean(data)) == variance(data).
    
    This property verifies that when the mean is explicitly provided as the xbar
    parameter to variance(), it produces the same result as when the mean is
    automatically calculated internally.
    
    Note: We constrain the float range to avoid extremely large numbers that can
    cause catastrophic loss of precision in floating-point arithmetic during
    variance calculations.
    """
    from statistics import variance, mean
    
    # Calculate variance without providing mean (automatic calculation)
    var_auto = variance(data)
    
    # Calculate mean explicitly and pass it to variance
    data_mean = mean(data)
    var_explicit = variance(data, data_mean)
    
    # The results should be identical (or very close due to floating point precision)
    # Use more relaxed tolerances to account for floating-point arithmetic limitations
    assert math.isclose(var_auto, var_explicit, rel_tol=1e-9, abs_tol=1e-9)

@given(st.lists(st.integers(min_value=-1000, max_value=1000), min_size=2, max_size=50))
def test_variance_with_explicit_mean_is_population_variance(data):
    """
    Test that variance(data, mean(data)) calculates population variance correctly.
    
    When mean is explicitly provided, variance() calculates population variance
    (dividing by n), which should equal the manual calculation of population variance.
    This tests that the variance function correctly implements the population variance
    formula when given an explicit mean parameter.
    """
    from statistics import variance, mean
    
    data_mean = mean(data)
    var_explicit = variance(data, data_mean)
    
    # Manual population variance calculation: sum of squared deviations divided by n
    manual_var = sum((x - data_mean) ** 2 for x in data) / len(data)
    
    # With integer data and exact arithmetic, these should be exactly equal
    assert var_explicit == manual_var

import math
from statistics import stdev, mean

@given(st.lists(st.floats(allow_nan=False, allow_infinity=False, min_value=-1e10, max_value=1e10), min_size=2, max_size=100))
def test_stdev_with_mean_equals_stdev_without_mean(data):
    """
    Test that stdev(data, mean(data)) == stdev(data).
    
    This property tests that passing the mean as the xbar parameter to stdev
    produces the same result as letting stdev calculate the mean internally.
    The standard deviation calculation should be identical in both cases.
    
    The float range is constrained to avoid extremely large numbers that cause
    floating-point precision issues during standard deviation calculations.
    """
    # Calculate stdev without providing xbar (mean calculated internally)
    stdev_without_mean = stdev(data)
    
    # Calculate mean separately and pass it as xbar parameter
    data_mean = mean(data)
    stdev_with_mean = stdev(data, data_mean)
    
    # The results should be equal (using isclose for floating point comparison)
    # Use a more lenient tolerance to account for floating-point precision
    assert math.isclose(stdev_with_mean, stdev_without_mean, rel_tol=1e-9, abs_tol=1e-9)

from statistics import mean, median, mode

@given(st.one_of(
    st.integers(),
    st.floats(allow_nan=False, allow_infinity=False),
    st.fractions(),
    st.decimals(allow_nan=False, allow_infinity=False)
))
def test_single_element_numeric_statistics_equality(x):
    """
    Test that for a single-element numeric dataset [x], mean([x]) == median([x]) == mode([x]) == x.
    
    This property should hold for numeric types: integers, floats, fractions, and decimals.
    All three statistical measures (mean, median, mode) work correctly with these types.
    """
    data = [x]
    
    mean_result = mean(data)
    median_result = median(data)
    mode_result = mode(data)
    
    # All three statistical measures should equal the single element
    assert mean_result == x, f"mean([{x}]) = {mean_result}, expected {x}"
    assert median_result == x, f"median([{x}]) = {median_result}, expected {x}"
    assert mode_result == x, f"mode([{x}]) = {mode_result}, expected {x}"
    
    # All three measures should be equal to each other
    assert mean_result == median_result == mode_result, \
        f"mean={mean_result}, median={median_result}, mode={mode_result} should all be equal"


@given(st.one_of(
    st.text().filter(lambda s: len(s) > 0),  # Filter out empty strings
    st.booleans()
))
def test_single_element_non_numeric_statistics_equality(x):
    """
    Test that for a single-element non-numeric dataset [x], median([x]) == mode([x]) == x.
    
    This property should hold for non-numeric types: non-empty strings and booleans.
    Note: mean() doesn't work reliably with non-numeric types, so we only test median and mode.
    Empty strings are filtered out because they can cause issues with statistical functions.
    """
    data = [x]
    
    median_result = median(data)
    mode_result = mode(data)
    
    # Both statistical measures should equal the single element
    assert median_result == x, f"median([{x}]) = {median_result}, expected {x}"
    assert mode_result == x, f"mode([{x}]) = {mode_result}, expected {x}"
    
    # Both measures should be equal to each other
    assert median_result == mode_result, \
        f"median={median_result}, mode={mode_result} should be equal"

import math
from decimal import Decimal
from fractions import Fraction

@given(
    value=st.one_of(
        st.integers(min_value=-(2**53-1), max_value=2**53-1),  # Safe integer range
        st.floats(allow_nan=False, allow_infinity=False),
        st.fractions(max_denominator=10**6),  # Limit denominator size
        st.decimals(allow_nan=False, allow_infinity=False, places=6)  # Limit decimal places
    ),
    size=st.integers(min_value=1, max_value=100)
)
def test_identical_elements_mean_median_mode_equality(value, size):
    """
    Test that for datasets with identical elements [x, x, ..., x],
    mean(data) == median(data) == mode(data) == x.
    
    This property should hold for any numeric type and any positive dataset size.
    The test uses approximate equality checks due to potential precision loss
    when statistical functions convert inputs to floating-point numbers.
    """
    # Create dataset with identical elements
    data = [value] * size
    
    # Calculate statistics
    calculated_mean = mean(data)
    calculated_median = median(data)
    calculated_mode = mode(data)
    
    # Use appropriate tolerance based on the numeric type
    if isinstance(value, float):
        # For floats, use standard relative tolerance
        rel_tol = 1e-9
        abs_tol = 1e-12
    else:
        # For exact numeric types (int, Fraction, Decimal), use tighter tolerance
        # to account for potential float conversion in statistical functions
        rel_tol = 1e-10
        abs_tol = 1e-15
    
    # Convert value to float for comparison since statistical functions may return floats
    expected_value = float(value)
    
    # Assert that all statistics equal the original value
    assert math.isclose(calculated_mean, expected_value, rel_tol=rel_tol, abs_tol=abs_tol), \
        f"Mean {calculated_mean} != {expected_value}"
    assert math.isclose(calculated_median, expected_value, rel_tol=rel_tol, abs_tol=abs_tol), \
        f"Median {calculated_median} != {expected_value}"
    assert math.isclose(calculated_mode, expected_value, rel_tol=rel_tol, abs_tol=abs_tol), \
        f"Mode {calculated_mode} != {expected_value}"
    
    # Assert that all statistics are equal to each other
    assert math.isclose(calculated_mean, calculated_median, rel_tol=rel_tol, abs_tol=abs_tol), \
        f"Mean {calculated_mean} != Median {calculated_median}"
    assert math.isclose(calculated_median, calculated_mode, rel_tol=rel_tol, abs_tol=abs_tol), \
        f"Median {calculated_median} != Mode {calculated_mode}"
    assert math.isclose(calculated_mean, calculated_mode, rel_tol=rel_tol, abs_tol=abs_tol), \
        f"Mean {calculated_mean} != Mode {calculated_mode}"